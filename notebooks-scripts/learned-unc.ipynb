{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose, Normalize\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import random_split\n",
    "import copy\n",
    "\n",
    "from NN_utils import *\n",
    "from NN_utils.train_and_eval import *\n",
    "from uncertainty import train_NN_with_g\n",
    "from uncertainty.losses import penalized_uncertainty\n",
    "import uncertainty.comparison as unc_comp\n",
    "import uncertainty.quantifications as unc\n",
    "\n",
    "\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "dev = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_train = transforms.Compose([\n",
    "                    transforms.RandomCrop(32, padding=4),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "transforms_ = transforms.Compose([\n",
    "transforms.ToTensor(),\n",
    "transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "training_data = datasets.CIFAR10(\n",
    "root=\"data\",\n",
    " train=True,\n",
    " download=True,\n",
    "transform=transforms_train)\n",
    "\n",
    "test_data = datasets.CIFAR10(\n",
    "root=\"data\",\n",
    "train=False,\n",
    "download=True,\n",
    "transform=transforms_)\n",
    "\n",
    "train_size = int(0.5*len(training_data))\n",
    "val_size = len(training_data) - train_size\n",
    "training_data, validation_data = random_split(training_data, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 12\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size,shuffle = True)\n",
    "validation_dataloader = DataLoader(validation_data, batch_size=batch_size,shuffle = True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NN_models.CIFAR10 import Model_CNN_with_g\n",
    "model = Model_CNN_with_g()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_metrics(model,data):\n",
    "    loss_criterion = nn.NLLLoss(reduction = 'sum')\n",
    "    model.eval()\n",
    "    dev = next(model.parameters()).device\n",
    "    total = 0\n",
    "    correct= 0\n",
    "    g_i = 0\n",
    "    bce = 0\n",
    "    with torch.no_grad():\n",
    "        for image,label in data:\n",
    "            image,label = image.to(dev), label.to(dev)\n",
    "            output = model(image)\n",
    "            g = model.get_g()\n",
    "            total += label.size(0)\n",
    "            correct += correct_total(output,label)\n",
    "            g_i += torch.sum(g).item()\n",
    "            bce += loss_criterion(output,label).item()\\\n",
    "\n",
    "    return (correct/total),g_i/total, bce/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(nn.Module):\n",
    "    def __init__(self,model,optimizer,loss_criterion, print_loss = True,keep_hist = True):\n",
    "        # adaptar keep hist para definir oq manter\\n\",\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_fn = loss_criterion\n",
    "        self.print_loss = print_loss\n",
    "        self.keep_hist = keep_hist\n",
    "\n",
    "        self.g_list = []\n",
    "        self.acc_list = []\n",
    "        self.bce_list = []\n",
    "\n",
    "    def fit(self,data,n_epochs):\n",
    "        for epoch in range(1,n_epochs+1):\n",
    "            train_NN_with_g(self.model,self.optimizer,data,self.loss_fn,1, self.print_loss, set_train_mode = True)\n",
    "            if self.keep_hist:\n",
    "                self.update_hist(data)\n",
    "\n",
    "    def fit_x(self,data,n_epochs,ignored_layers = ['fc_g_layer']):\n",
    "        loss_criterion = copy.copy(self.loss_fn.criterion)\n",
    "        loss_criterion.reduction = 'mean'\n",
    "        ignore_layers(model,ignored_layers,reset = True)\n",
    "        for epoch in range(1,n_epochs+1):\n",
    "            train_NN(self.model,self.optimizer,data,loss_criterion,1, self.print_loss, set_train_mode = True)\n",
    "            if self.keep_hist:\n",
    "                self.update_hist(data)\n",
    "\n",
    "    def fit_g(self,data,n_epochs,ignored_layers = ['conv_layer','fc_x_layer']):\n",
    "        try:\n",
    "            self.loss_fn.update_L0(self.bce_list[-1])\n",
    "        except:\n",
    "            self.loss_fn.update_L0(np.log(10))\n",
    "            ignore_layers(model,ignored_layers, reset = True)\n",
    "        for epoch in range(1,n_epochs+1):\n",
    "            train_NN_with_g(self.model,self.optimizer,data,self.loss_fn,1, self.print_loss, set_train_mode = True)\n",
    "            if self.keep_hist:\n",
    "                self.update_hist(data)\n",
    "\n",
    "            self.loss_fn.update_L0(self.bce_list[-1])\n",
    "\n",
    "    def update_hist(self,data):\n",
    "        acc, g, bce =  model_metrics(self.model,data)\n",
    "        self.g_list.append(g)\n",
    "        self.acc_list.append(acc)\n",
    "        self.bce_list.append(bce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 , loss =  2.294319826787813\n",
      "Epoch  1 , loss =  2.19673604276496\n",
      "Epoch  1 , loss =  1.8909364544041096\n",
      "Epoch  1 , loss =  1.7203832686862652\n",
      "Epoch  1 , loss =  1.6055224000149175\n",
      "Epoch  1 , loss =  1.5049649229891697\n",
      "Epoch  1 , loss =  1.4192280562562356\n",
      "Epoch  1 , loss =  1.3415547056756414\n",
      "Epoch  1 , loss =  1.2797027842325808\n",
      "Epoch  1 , loss =  1.212885246424437\n",
      "Epoch  1 , loss =  1.1562833506435213\n",
      "Epoch  1 , loss =  1.1094985993260844\n",
      "Epoch  1 , loss =  1.0602683343579582\n",
      "Epoch  1 , loss =  1.0184231218229443\n",
      "Epoch  1 , loss =  0.9824947948547906\n"
     ]
    }
   ],
   "source": [
    "model = Model_CNN_with_g()\n",
    "model = model.to(dev)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "loss_criterion = nn.NLLLoss(reduction = 'none')\n",
    "loss_fn = penalized_uncertainty(loss_criterion,np.log(10))\n",
    "\n",
    "model_trainer = Trainer(model,optimizer,loss_fn, print_loss = True,keep_hist = True)\n",
    "model_trainer.fit(train_dataloader,30)\n",
    "acc, g, bce = model_metrics(model,train_dataloader)\n",
    "print('Conjunto de treinamento: acc = ', acc, 'média de g = ', g, 'média de bce = ', bce, '\\n')\n",
    "acc, g, bce = model_metrics(model,test_dataloader)\n",
    "print('Conjunto de teste: acc = ', acc, 'média de g = ', g, 'média de bce = ', bce, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Model_CNN_with_g()\\n\",\n",
    "model_2 = model.to(dev)\\n\",\n",
    "optimizer = torch.optim.SGD(model_2.parameters(), lr=1e-3)\n",
    "\n",
    "model_trainer_2 = Trainer(model_2,optimizer,loss_fn, print_loss = True,keep_hist = True)\n",
    "model_trainer_2.fit_x(train_dataloader,30)\n",
    "model_trainer_2.fit_g(train_dataloader,15)\n",
    "\n",
    "acc, g, bce = model_metrics(model_2,train_dataloader)\n",
    "print('Conjunto de treinamento: acc = ', acc, 'média de g = ', g, 'média de bce = ', bce, '\\n')\n",
    "acc, g, bce = model_metrics(model_2,test_dataloader)\n",
    "print('Conjunto de teste: acc = ', acc, 'média de g = ', g, 'média de bce = ', bce, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = Model_CNN_with_g()\n",
    "model_3 = model.to(dev)\n",
    "optimizer = torch.optim.SGD(model_3.parameters(), lr=1e-3)\n",
    "\n",
    "model_trainer_3 = Trainer(model_3,optimizer,loss_fn, print_loss = True,keep_hist = True)\n",
    "model_trainer_3.fit_x(train_dataloader,15)\n",
    "model_trainer_3.fit_g(validation_dataloader,15)\n",
    "\n",
    "acc, g, bce = model_metrics(model_3,train_dataloader)\n",
    "print('Conjunto de treinamento: acc = ', acc, 'média de g = ', g, 'média de bce = ', bce, '\\n')\n",
    "acc, g, bce = model_metrics(model_3,test_dataloader)\n",
    "print('Conjunto de teste: acc = ', acc, 'média de g = ', g, 'média de bce = ', bce, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
