{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libs and pre-definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "### Bibliotecas padrões python e utils pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose, Normalize\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import random_split\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Define o computador utilizado como cuda (gpu) se existir ou cpu caso contrário\n",
    "print(torch.cuda.is_available())\n",
    "dev = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "### Bibliotecas desenvolvidas\n",
    "\n",
    "https://github.com/lfpc/Uncertainty_Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NN_utils import *\n",
    "from NN_utils.train_and_eval import *\n",
    "from uncertainty import train_NN_with_g\n",
    "from uncertainty.losses import penalized_uncertainty\n",
    "from NN_models import Model_CNN\n",
    "import uncertainty.comparison as unc_comp\n",
    "import uncertainty.quantifications as unc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data download and transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_train = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    #transforms.RandomCrop(32, padding=4),\n",
    "                    #transforms.RandomHorizontalFlip(),\n",
    "                    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "transforms_test = transforms.Compose([\n",
    "transforms.ToTensor(),\n",
    "transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "training_data = datasets.CIFAR10(\n",
    "root=\"data\",\n",
    " train=True,\n",
    " download=True,\n",
    "transform=transforms_train)\n",
    "\n",
    "test_data = datasets.CIFAR10(\n",
    "root=\"data\",\n",
    "train=False,\n",
    "download=True,\n",
    "transform=transforms_test)\n",
    "\n",
    "train_size = int(0.85*len(training_data))\n",
    "val_size = len(training_data) - train_size\n",
    "training_data, validation_data = random_split(training_data, [train_size, val_size])\n",
    "\n",
    "#validation_data = copy.deepcopy(validation_data)\n",
    "#validation_data.dataset.transforms = transforms_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 12\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size,shuffle = True)\n",
    "validation_dataloader = DataLoader(validation_data, batch_size=batch_size,shuffle = False)\n",
    "test_dataloader = DataLoader(test_data, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN classes and Trainer class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "### Definição da classe da rede neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "class Model_CNN(nn.Module):\n",
    "    \"\"\"CNN.\"\"\"\n",
    "\n",
    "    def __init__(self,n_classes=10):\n",
    "        \"\"\"CNN Builder.\"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        conv_layer = [\n",
    "\n",
    "            # Conv Layer block 1\n",
    "            nn.Conv2d(in_channels=3, out_channels=int(16), kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(int(16)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=int(16), out_channels=int(32), kernel_size=3, padding=1),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "        ]\n",
    "        \n",
    "        fc_layer = [\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(8192, int(1024)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(int(1024), int(512)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.2)]\n",
    "        \n",
    "        main_layer = conv_layer+fc_layer\n",
    "        \n",
    "        self.main_layer = nn.Sequential(*main_layer)\n",
    "        \n",
    "        self.classifier_layer = nn.Sequential(\n",
    "            nn.Linear(int(512), n_classes),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Perform forward.\"\"\"\n",
    "    \n",
    "        x = self.main_layer(x)\n",
    "\n",
    "\n",
    "        y = self.classifier_layer(x)\n",
    "\n",
    "        y = y.float()\n",
    "\n",
    "        \n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "class Model_CNN_with_g(nn.Module):\n",
    "    \"\"\"CNN.\"\"\"\n",
    "\n",
    "    def __init__(self,n_classes=10):\n",
    "        \"\"\"CNN Builder.\"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.return_g = False\n",
    "        \n",
    "        conv_layer = [\n",
    "\n",
    "            # Conv Layer block 1\n",
    "            nn.Conv2d(in_channels=3, out_channels=int(16), kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(int(16)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=int(16), out_channels=int(32), kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "        ]\n",
    "        \n",
    "        fc_layer = [\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(8192, int(1024)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(int(1024), int(512)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.2)]\n",
    "        \n",
    "        \n",
    "        main_layer = conv_layer+fc_layer\n",
    "        \n",
    "        self.main_layer = nn.Sequential(*main_layer)\n",
    "        \n",
    "\n",
    "        self.classifier_layer = nn.Sequential(\n",
    "            nn.Linear(int(512), n_classes),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "        \n",
    "        '''self.fc_g_layer = nn.Sequential(\n",
    "            \n",
    "            nn.Linear(int(512), 1),\n",
    "            nn.Sigmoid()\n",
    "        )'''\n",
    "        \n",
    "        self.g_layer = nn.Sequential(\n",
    "            \n",
    "            nn.Linear(int(512), n_classes),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Perform forward.\"\"\"\n",
    "    \n",
    "        x = self.main_layer(x)\n",
    "\n",
    "\n",
    "        y = self.classifier_layer(x)\n",
    "\n",
    "        self.g = self.g_layer(x)\n",
    "        self.g = torch.max(self.g,dim=1).values\n",
    "\n",
    "        self.g = (self.g).float()\n",
    "        y = y.float()\n",
    "\n",
    "        \n",
    "        if self.return_g:\n",
    "            return y,self.g\n",
    "        else:\n",
    "            return y\n",
    "    \n",
    "    def get_g(self):\n",
    "        return self.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_CNN_with_g_2(nn.Module):\n",
    "    \"\"\"CNN.\"\"\"\n",
    "\n",
    "    def __init__(self,n_classes=10):\n",
    "        \"\"\"CNN Builder.\"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.return_g = False\n",
    "        \n",
    "        conv_layer = [\n",
    "\n",
    "            # Conv Layer block 1\n",
    "            nn.Conv2d(in_channels=3, out_channels=int(16), kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(int(16)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=int(16), out_channels=int(32), kernel_size=3, padding=1),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "        ]\n",
    "        \n",
    "        fc_layer = [\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(8192, int(1024)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(int(1024), int(512)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.2)]\n",
    "        \n",
    "        \n",
    "        main_layer = conv_layer+fc_layer\n",
    "        \n",
    "        self.main_layer = nn.Sequential(*main_layer)\n",
    "        \n",
    "\n",
    "        self.classifier_layer = nn.Sequential(\n",
    "            nn.Linear(int(512), n_classes),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "        \n",
    "        '''self.fc_g_layer = nn.Sequential(\n",
    "            \n",
    "            nn.Linear(int(512), 1),\n",
    "            nn.Sigmoid()\n",
    "        )'''\n",
    "        \n",
    "        self.g_layer = nn.Sequential(\n",
    "            \n",
    "            nn.Linear(n_classes, 64),\n",
    "            nn.ReLU(inplace=True), #tanh\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Perform forward.\"\"\"\n",
    "    \n",
    "        x = self.main_layer(x)\n",
    "\n",
    "\n",
    "        y = self.classifier_layer(x)\n",
    "\n",
    "        self.g = self.g_layer(y)\n",
    "\n",
    "        self.g = (self.g).float()\n",
    "        y = y.float()\n",
    "\n",
    "        \n",
    "        if self.return_g:\n",
    "            return y,self.g\n",
    "        else:\n",
    "            return y\n",
    "    \n",
    "    def get_g(self):\n",
    "        return self.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_CNN_with_g_3(nn.Module):\n",
    "    \"\"\"CNN.\"\"\"\n",
    "\n",
    "    def __init__(self,n_classes=10):\n",
    "        \"\"\"CNN Builder.\"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.return_g = False\n",
    "        \n",
    "        conv_layer = [\n",
    "\n",
    "            # Conv Layer block 1\n",
    "            nn.Conv2d(in_channels=3, out_channels=int(16), kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(int(16)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=int(16), out_channels=int(32), kernel_size=3, padding=1),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "        ]\n",
    "        \n",
    "        fc_layer = [\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(8192, int(1024)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(int(1024), int(512)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.2)]\n",
    "        \n",
    "        \n",
    "        main_layer = conv_layer+fc_layer\n",
    "        \n",
    "        self.main_layer = nn.Sequential(*main_layer)\n",
    "        \n",
    "\n",
    "        self.classifier_layer = nn.Sequential(\n",
    "            nn.Linear(int(512), n_classes),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "        \n",
    "        '''self.fc_g_layer = nn.Sequential(\n",
    "            \n",
    "            nn.Linear(int(512), 1),\n",
    "            nn.Sigmoid()\n",
    "        )'''\n",
    "        \n",
    "        self.g_layer = nn.Sequential(\n",
    "            \n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Perform forward.\"\"\"\n",
    "    \n",
    "        x = self.main_layer(x)\n",
    "\n",
    "\n",
    "        y = self.classifier_layer(x)\n",
    "\n",
    "        self.g = self.g_layer(x)\n",
    "\n",
    "        self.g = (self.g).float()\n",
    "        y = y.float()\n",
    "\n",
    "        \n",
    "        if self.return_g:\n",
    "            return y,self.g\n",
    "        else:\n",
    "            return y\n",
    "    \n",
    "    def get_g(self):\n",
    "        return self.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_CNN_with_g_4(nn.Module): #realizar concatenação de x com y e etc\n",
    "    \"\"\"CNN.\"\"\"\n",
    "\n",
    "    def __init__(self,n_classes=10):\n",
    "        \"\"\"CNN Builder.\"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.return_g = False\n",
    "        \n",
    "        conv_layer = [\n",
    "\n",
    "            # Conv Layer block 1\n",
    "            nn.Conv2d(in_channels=3, out_channels=int(16), kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(int(16)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=int(16), out_channels=int(32), kernel_size=3, padding=1),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "        ]\n",
    "        \n",
    "        fc_layer = [\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(8192, int(1024)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(int(1024), int(512)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.2)]\n",
    "        \n",
    "        \n",
    "        main_layer = conv_layer+fc_layer\n",
    "        \n",
    "        self.main_layer = nn.Sequential(*main_layer)\n",
    "        \n",
    "\n",
    "        self.classifier_layer = nn.Sequential(\n",
    "            nn.Linear(int(512), n_classes),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "        \n",
    "        '''self.fc_g_layer = nn.Sequential(\n",
    "            \n",
    "            nn.Linear(int(512), 1),\n",
    "            nn.Sigmoid()\n",
    "        )'''\n",
    "        \n",
    "        self.g_layer_1 = nn.Sequential(\n",
    "            \n",
    "            nn.Linear(512, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "        self.g_layer_2 = nn.Sequential(\n",
    "            \n",
    "            nn.Linear(20, 32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Perform forward.\"\"\"\n",
    "    \n",
    "        x = self.main_layer(x)\n",
    "\n",
    "\n",
    "        y = self.classifier_layer(x)\n",
    "\n",
    "        self.g = self.g_layer_1(x)\n",
    "        self.g = torch.cat((self.g,y),dim=1)\n",
    "        self.g = self.g_layer_2(self.g)\n",
    "\n",
    "        self.g = (self.g).float()\n",
    "        y = y.float()\n",
    "        \n",
    "        if self.return_g:\n",
    "            return y,self.g\n",
    "        else:\n",
    "            return y\n",
    "    \n",
    "    def get_g(self):\n",
    "        return self.g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "### Definição das classes de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class hist_train():\n",
    "    def __init__(self,model,loss_criterion,data):\n",
    "        \n",
    "        self.model = model\n",
    "        self.loss_criterion = loss_criterion\n",
    "        self.data = data\n",
    "        \n",
    "        self.acc_list = []\n",
    "        self.loss_list = []\n",
    "    \n",
    "        \n",
    "    def update_hist(self,data = None):\n",
    "        \n",
    "        if data is None:\n",
    "            data = self.data\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            loss = 0\n",
    "            hits = 0\n",
    "            for image,label in data:\n",
    "                image,label = image.to(dev),label.to(dev)\n",
    "                output = self.model(image)\n",
    "                loss += self.loss_criterion(output,label).item()\n",
    "                hits += correct_total(output,label)\n",
    "            \n",
    "            acc = hits/len(data.dataset)\n",
    "            loss = loss/len(data.dataset)\n",
    "            self.acc_list.append(acc)\n",
    "            self.loss_list.append(loss)\n",
    "                \n",
    "    def __str__(self):\n",
    "        pass\n",
    "            \n",
    "                \n",
    "class hist_train_g(hist_train):\n",
    "    def __init__(self,model,loss_criterion,data,c = 0):\n",
    "        super().__init__(model,loss_criterion,data)\n",
    "        \n",
    "        self.c = c\n",
    "        self.g_list = []\n",
    "        if c>0:\n",
    "            self.acc_c_g = []\n",
    "            self.acc_c_mcp = []\n",
    "            \n",
    "    def update_hist(self,data = None):\n",
    "        \n",
    "        if data is None:\n",
    "            data = self.data\n",
    "            \n",
    "        with torch.no_grad():\n",
    "\n",
    "            label, output, g = accumulate_results(self.model,data)\n",
    "            loss = self.loss_criterion(output,label).item()\n",
    "            output = torch.exp(output)\n",
    "            acc = correct_total(output,label)/label.size(0)\n",
    "\n",
    "            self.g_list.append(torch.mean(g).item())\n",
    "            self.acc_list.append(acc)\n",
    "            self.loss_list.append(loss)\n",
    "\n",
    "            mcp = unc.MCP_unc(output)\n",
    "\n",
    "            if self.c>0:\n",
    "                self.acc_c_g.append(unc_comp.acc_coverage(output,label,1-g,self.c))\n",
    "                self.acc_c_mcp.append(unc_comp.acc_coverage(output,label,mcp,self.c))\n",
    "            \n",
    "        \n",
    "    \n",
    "class Trainer():\n",
    "    def __init__(self,model,optimizer,loss_criterion,training_data,validation_data):\n",
    "        super().__init__()\n",
    "        \n",
    "        loss_crit = copy.deepcopy(loss_criterion.criterion)\n",
    "        loss_crit.reduction = 'sum'\n",
    "        \n",
    "        self.hist_train = hist_train(model,loss_crit,training_data)\n",
    "        self.hist_val = hist_train(model,loss_crit,validation_data)\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_fn = loss_criterion\n",
    "\n",
    "    def fit(self,data,n_epochs):\n",
    "        loss_criterion = copy.deepcopy(self.loss_fn.criterion)\n",
    "        loss_criterion.reduction = 'mean'\n",
    "        for epoch in range(1,n_epochs+1):\n",
    "            loss = train_NN(self.model,self.optimizer,data,loss_criterion,1, print_loss = False, set_train_mode = True)\n",
    "            print('Epoch ', epoch+1, ', loss = ', loss)\n",
    "            self.hist_train.update_hist()\n",
    "            self.hist_val.update_hist()\n",
    "            \n",
    "            \n",
    "            \n",
    "class Trainer_with_g(Trainer):\n",
    "    def __init__(self,model,optimizer,loss_fn,training_data,validation_data, c = 0.2):\n",
    "        super().__init__(model,optimizer,loss_fn,training_data,validation_data)\n",
    "        \n",
    "        loss_criterion = copy.deepcopy(loss_fn.criterion)\n",
    "        loss_criterion.reduction = 'mean'\n",
    "        \n",
    "        self.hist_train = hist_train_g(model,loss_criterion,training_data, c=c)\n",
    "        self.hist_val = hist_train_g(model,loss_criterion,validation_data,c=c)\n",
    "    \n",
    "    def fit_all(self,data,n_epochs):\n",
    "        unfreeze_params(self.model)\n",
    "        for epoch in range(1,n_epochs+1):\n",
    "            train_NN_with_g(self.model,self.optimizer,data,self.loss_fn,n_epochs=1, print_loss = True,set_train_mode = True)\n",
    "            self.hist_train.update_hist()\n",
    "            self.hist_val.update_hist()\n",
    "            self.loss_fn.update_L0(self.hist_train.loss_list[-1])\n",
    "\n",
    "    def fit_g(self,data,n_epochs,ignored_layers = ['main_layer','classifier_layer']):\n",
    "        \n",
    "        loss = self.hist_val.loss_list[-1]\n",
    "        self.loss_fn.update_L0(loss)\n",
    "        ignore_layers(self.model,ignored_layers, reset = True)\n",
    "        for epoch in range(1,n_epochs+1):\n",
    "            train_NN_with_g(self.model,self.optimizer,data,self.loss_fn,n_epochs=1, print_loss = True,set_train_mode = False)\n",
    "            self.hist_train.update_hist()\n",
    "            self.hist_val.update_hist()\n",
    "            ignore_layers(self.model,ignored_layers, reset = False)\n",
    "            loss =  self.hist_train.loss_list[-1]#self.hist_val.loss_list[-1]\n",
    "            self.loss_fn.update_L0(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testes e treinamentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "### Definição da perda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_criterion = nn.NLLLoss(reduction = 'none')\n",
    "loss_fn = penalized_uncertainty(loss_criterion,np.log(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class aux_loss_fs(nn.Module):\n",
    "    \n",
    "    def __init__(self,loss_criterion):\n",
    "        super().__init__()\n",
    "        self.L0 = 0\n",
    "        self.criterion = loss_criterion\n",
    "        \n",
    "    def forward(self, y_pred,g,y_true):\n",
    "        g = g.view(-1)\n",
    "        y_pred = torch.exp(y_pred)\n",
    "        right = correct_class(y_pred,y_true).float()\n",
    "        #loss = torch.square(g.view(-1)-MCP)\n",
    "        loss = self.criterion(g,right)\n",
    "        loss = torch.mean(loss)\n",
    "        return loss\n",
    "    \n",
    "    def update_L0(self,new_L0):\n",
    "        with torch.no_grad():\n",
    "            self.L0 = new_L0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class aux_loss(nn.Module):\n",
    "    \n",
    "    def __init__(self,loss_criterion):\n",
    "        super().__init__()\n",
    "        self.L0 = 0\n",
    "        self.criterion = loss_criterion\n",
    "        \n",
    "    def forward(self, y_pred,g,y_true):\n",
    "        g = g.view(-1)\n",
    "        y_pred = torch.exp(y_pred)\n",
    "        MCP = unc.get_MCP(y_pred)\n",
    "        loss = torch.square(g.view(-1)-MCP)\n",
    "        loss = torch.mean(loss)\n",
    "        return loss\n",
    "    \n",
    "    def update_L0(self,new_L0):\n",
    "        with torch.no_grad():\n",
    "            self.L0 = new_L0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento dos modelos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2 , loss =  2.0140752805820767\n",
      "Epoch  3 , loss =  1.5965657266669864\n",
      "Epoch  4 , loss =  1.4195810904834716\n",
      "Epoch  5 , loss =  1.3122157062567406\n",
      "Epoch  6 , loss =  1.2305067602875273\n",
      "Epoch  7 , loss =  1.1642795500194603\n",
      "Epoch  8 , loss =  1.0978246376482126\n",
      "Epoch  9 , loss =  1.0404561478486847\n"
     ]
    }
   ],
   "source": [
    "model = Model_CNN(10).cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "loss_criterion = nn.NLLLoss(reduction = 'none')\n",
    "loss_fn = penalized_uncertainty(loss_criterion,np.log(2))\n",
    "\n",
    "model_trainer = Trainer(model,optimizer,loss_fn, train_dataloader,validation_dataloader)\n",
    "model_trainer.fit(train_dataloader,70)\n",
    "state_dict  = model.state_dict()\n",
    "\n",
    "acc = model_acc(model,train_dataloader)\n",
    "print('Conjunto de treinamento: acc = ', acc)\n",
    "acc = model_acc(model,test_dataloader)\n",
    "print('Conjunto de teste: acc = ', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "#### Perda padrão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 , loss =  2.301543180919649\n",
      "Epoch  1 , loss =  2.27968191595686\n",
      "Epoch  1 , loss =  2.2367758080489484\n",
      "Epoch  1 , loss =  1.9105248117702684\n",
      "Epoch  1 , loss =  1.6132616058101363\n",
      "Epoch  1 , loss =  1.4148842599653106\n",
      "Epoch  1 , loss =  1.32431927582492\n",
      "Epoch  1 , loss =  1.2696973100380329\n",
      "Epoch  1 , loss =  1.2121404495062902\n",
      "Epoch  1 , loss =  1.1628997752486077\n",
      "Epoch  1 , loss =  1.121644231490265\n",
      "Epoch  1 , loss =  1.0931199324932024\n",
      "Epoch  1 , loss =  1.0532309755910123\n",
      "Epoch  1 , loss =  1.0348145226463634\n",
      "Epoch  1 , loss =  0.9927366655267341\n",
      "Epoch  1 , loss =  0.968609496547232\n",
      "Epoch  1 , loss =  0.9298620669014503\n",
      "Epoch  1 , loss =  0.9369798226840479\n",
      "Epoch  1 , loss =  0.8788265892673117\n",
      "Epoch  1 , loss =  0.8587591381883433\n",
      "Epoch  1 , loss =  0.827658844635286\n",
      "Epoch  1 , loss =  0.8010640285029915\n",
      "Epoch  1 , loss =  0.7776031847107148\n",
      "Epoch  1 , loss =  0.7575727672411318\n",
      "Epoch  1 , loss =  0.7355670065554369\n",
      "Epoch  1 , loss =  0.7174429142335456\n",
      "Epoch  1 , loss =  0.6970299499636313\n",
      "Epoch  1 , loss =  0.6699449273656143\n",
      "Epoch  1 , loss =  0.6511129814940008\n",
      "Epoch  1 , loss =  0.6370245800566565\n",
      "Epoch  1 , loss =  0.6159672399131946\n",
      "Epoch  1 , loss =  0.6030650670408261\n",
      "Epoch  1 , loss =  0.5881515538066474\n",
      "Epoch  1 , loss =  0.5687060003846732\n",
      "Epoch  1 , loss =  0.5562204733861159\n",
      "Epoch  1 , loss =  0.5321333155894199\n",
      "Epoch  1 , loss =  0.5318806377391503\n",
      "Epoch  1 , loss =  0.5026866207724907\n",
      "Epoch  1 , loss =  0.4914079595468665\n",
      "Epoch  1 , loss =  0.4737023220711479\n",
      "Epoch  1 , loss =  0.4601225827703329\n",
      "Epoch  1 , loss =  0.4501258860106087\n",
      "Epoch  1 , loss =  0.4470221537261579\n",
      "Epoch  1 , loss =  0.4292293879009451\n",
      "Epoch  1 , loss =  0.4229219851290722\n",
      "Epoch  1 , loss =  0.3994071980226282\n",
      "Epoch  1 , loss =  0.3922517206109661\n",
      "Epoch  1 , loss =  0.38037603145085574\n",
      "Epoch  1 , loss =  0.36770860839031433\n",
      "Epoch  1 , loss =  0.3591207870440521\n",
      "Epoch  1 , loss =  0.3498611194441828\n",
      "Epoch  1 , loss =  0.3394284494965848\n",
      "Epoch  1 , loss =  0.32971808391942403\n",
      "Epoch  1 , loss =  0.31749869788823865\n",
      "Epoch  1 , loss =  0.3286907706169894\n",
      "Epoch  1 , loss =  0.3049031895343982\n",
      "Epoch  1 , loss =  0.29706898987301655\n",
      "Epoch  1 , loss =  0.28682812865568985\n",
      "Epoch  1 , loss =  0.28194084273202147\n",
      "Epoch  1 , loss =  0.26898133227120996\n",
      "Epoch  1 , loss =  0.26384509149581226\n",
      "Epoch  1 , loss =  0.2573015415690785\n",
      "Epoch  1 , loss =  0.2496923218475458\n",
      "Epoch  1 , loss =  0.2454841538005835\n",
      "Epoch  1 , loss =  0.23817646159474407\n",
      "Epoch  1 , loss =  0.2304001366630205\n",
      "Epoch  1 , loss =  0.22447186415959286\n",
      "Epoch  1 , loss =  0.21475096585051293\n",
      "Epoch  1 , loss =  0.2116129266351613\n",
      "Epoch  1 , loss =  0.20424814355091092\n",
      "Epoch  1 , loss =  0.1986925894727658\n",
      "Epoch  1 , loss =  0.1911736734735741\n",
      "Epoch  1 , loss =  0.1871808978982947\n",
      "Epoch  1 , loss =  0.18863131320311724\n",
      "Epoch  1 , loss =  0.177591003331742\n",
      "Epoch  1 , loss =  0.1706802134115758\n",
      "Epoch  1 , loss =  0.16597187237257693\n",
      "Epoch  1 , loss =  0.16224988288102005\n",
      "Epoch  1 , loss =  0.15649361802051542\n",
      "Epoch  1 , loss =  0.15150132194137225\n",
      "Epoch  1 , loss =  0.14698784645091487\n",
      "Epoch  1 , loss =  0.1411834424577195\n",
      "Epoch  1 , loss =  0.13803770032804408\n",
      "Epoch  1 , loss =  0.13368825524896047\n",
      "Epoch  1 , loss =  0.12990508973953446\n",
      "Epoch  1 , loss =  0.12449007682864596\n",
      "Epoch  1 , loss =  0.11868528514442611\n",
      "Epoch  1 , loss =  0.11674335401848102\n",
      "Epoch  1 , loss =  0.11329007010687646\n",
      "Epoch  1 , loss =  0.10712069907514374\n",
      "Epoch  1 , loss =  0.1036998023346586\n",
      "Epoch  1 , loss =  0.10595137625459407\n",
      "Epoch  1 , loss =  0.09759458574692007\n",
      "Epoch  1 , loss =  0.09403188057590375\n",
      "Epoch  1 , loss =  0.09251983635343679\n",
      "Epoch  1 , loss =  0.08998424720518945\n",
      "Epoch  1 , loss =  0.08643372097929988\n",
      "Epoch  1 , loss =  0.08201167858778938\n",
      "Epoch  1 , loss =  0.07937424097282214\n",
      "Epoch  1 , loss =  0.07511826452853963\n",
      "Epoch  1 , loss =  0.07316247914042975\n",
      "Epoch  1 , loss =  0.07114562401069482\n",
      "Epoch  1 , loss =  0.07094680694378738\n",
      "Epoch  1 , loss =  0.0655056093562583\n",
      "Epoch  1 , loss =  0.0635343568025609\n",
      "Epoch  1 , loss =  0.06059647642102079\n",
      "Epoch  1 , loss =  0.05948956301051612\n",
      "Epoch  1 , loss =  0.05602664463916838\n",
      "Epoch  1 , loss =  0.05408049440211214\n",
      "Epoch  1 , loss =  0.05193804974261096\n",
      "Epoch  1 , loss =  0.05070755164478687\n",
      "Epoch  1 , loss =  0.04912210035390317\n",
      "Epoch  1 , loss =  0.046321341478857296\n",
      "Epoch  1 , loss =  0.044444028841871146\n",
      "Epoch  1 , loss =  0.04147134027720567\n",
      "Epoch  1 , loss =  0.04273370375190475\n",
      "Epoch  1 , loss =  0.04094148254113899\n",
      "Epoch  1 , loss =  0.04008241436445669\n",
      "Epoch  1 , loss =  0.0362858905463928\n",
      "Epoch  1 , loss =  0.035263197168232\n",
      "Epoch  1 , loss =  0.03360309552132188\n",
      "Epoch  1 , loss =  0.031936560046378175\n",
      "Epoch  1 , loss =  0.030724928111724625\n",
      "Epoch  1 , loss =  0.029297572743020875\n",
      "Epoch  1 , loss =  0.029929279907817664\n",
      "Epoch  1 , loss =  0.03007962440470137\n",
      "Epoch  1 , loss =  0.026078504335469415\n",
      "Epoch  1 , loss =  0.026956476182033312\n",
      "Epoch  1 , loss =  0.025275168474287058\n",
      "Epoch  1 , loss =  0.024810500429834875\n",
      "Epoch  1 , loss =  0.02366453066445166\n",
      "Epoch  1 , loss =  0.02186662086598891\n",
      "Epoch  1 , loss =  0.021794733039707317\n",
      "Epoch  1 , loss =  0.021012238086858134\n",
      "Epoch  1 , loss =  0.024912683765955207\n",
      "Epoch  1 , loss =  0.019656865140512576\n",
      "Epoch  1 , loss =  0.025543884996359355\n",
      "Epoch  1 , loss =  0.01817355142103989\n",
      "Epoch  1 , loss =  0.01883878435789249\n",
      "Epoch  1 , loss =  0.01728458730643232\n",
      "Epoch  1 , loss =  0.017176157108436382\n",
      "Epoch  1 , loss =  0.017267192648502527\n",
      "Epoch  1 , loss =  0.015233118108013274\n",
      "Epoch  1 , loss =  0.016004874738446532\n",
      "Epoch  1 , loss =  0.015071971822813477\n",
      "Epoch  1 , loss =  0.015332372906937912\n",
      "Epoch  1 , loss =  0.014846105830882559\n",
      "Epoch  1 , loss =  0.013875949864788087\n",
      "Epoch  1 , loss =  0.0136091403637785\n",
      "Epoch  1 , loss =  0.012724849766540093\n",
      "Epoch  1 , loss =  0.012696036276043899\n",
      "Epoch  1 , loss =  0.01137455734331197\n",
      "Epoch  1 , loss =  0.011180496739700764\n",
      "Epoch  1 , loss =  0.011127853588190456\n",
      "Epoch  1 , loss =  0.010023801263402974\n",
      "Epoch  1 , loss =  0.01026581890575989\n",
      "Epoch  1 , loss =  0.010614585411479797\n",
      "Epoch  1 , loss =  0.009956114744313455\n",
      "Epoch  1 , loss =  0.010556783016646898\n",
      "Epoch  1 , loss =  0.01025682488711939\n",
      "Epoch  1 , loss =  0.009037300237562081\n",
      "Epoch  1 , loss =  0.008986036408539306\n",
      "Epoch  1 , loss =  0.009066672305228556\n",
      "Epoch  1 , loss =  0.008627675299180031\n",
      "Epoch  1 , loss =  0.008320583116660448\n",
      "Epoch  1 , loss =  0.008366491643339606\n",
      "Epoch  1 , loss =  0.007924360097142027\n",
      "Epoch  1 , loss =  0.007551265169689492\n",
      "Epoch  1 , loss =  0.007867609738844206\n",
      "Epoch  1 , loss =  0.007186471741293667\n",
      "Epoch  1 , loss =  0.00672647279534821\n",
      "Epoch  1 , loss =  0.007592523224319576\n",
      "Epoch  1 , loss =  0.006359194334227824\n",
      "Epoch  1 , loss =  0.0070123006718385466\n",
      "Epoch  1 , loss =  0.006884586227298873\n",
      "Epoch  1 , loss =  0.006543205381119121\n",
      "Epoch  1 , loss =  0.006691838027997482\n",
      "Epoch  1 , loss =  0.006208171340026106\n",
      "Epoch  1 , loss =  0.006176677864145856\n",
      "Epoch  1 , loss =  0.006324608015108308\n",
      "Epoch  1 , loss =  0.00617817489839241\n",
      "Epoch  1 , loss =  0.0060075636198108524\n",
      "Epoch  1 , loss =  0.006098329218854493\n",
      "Epoch  1 , loss =  0.006356316615449673\n",
      "Epoch  1 , loss =  0.00570029850386518\n",
      "Epoch  1 , loss =  0.005723684310816062\n",
      "Epoch  1 , loss =  0.004902577652005776\n",
      "Epoch  1 , loss =  0.005078872364774078\n",
      "Epoch  1 , loss =  0.004695201398778359\n",
      "Epoch  1 , loss =  0.004536280825893446\n",
      "Epoch  1 , loss =  0.00433874818145829\n",
      "Epoch  1 , loss =  0.004675640245911398\n",
      "Epoch  1 , loss =  0.004666896112549672\n",
      "Epoch  1 , loss =  0.004749676025736701\n",
      "Epoch  1 , loss =  0.004553224540600592\n",
      "Epoch  1 , loss =  0.004169469947812914\n",
      "Epoch  1 , loss =  0.00513037724550126\n",
      "Epoch  1 , loss =  0.0047453678791307494\n",
      "Epoch  1 , loss =  0.004674056944816727\n",
      "Epoch  1 , loss =  0.004527215317157828\n",
      "Conjunto de treinamento: acc =  0.9999529411764706 média de g =  0.6109681127604316 média de bce =  0.003648386540057682 \n",
      "\n",
      "Conjunto de teste: acc =  0.7329 média de g =  0.5739272632598877 média de bce =  1.3313006332397461 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_1 = Model_CNN_with_g()\n",
    "model_1 = model_1.to(dev)\n",
    "optimizer = torch.optim.SGD(model_1.parameters(), lr=1e-3)\n",
    "\n",
    "loss_criterion = nn.NLLLoss(reduction = 'none')\n",
    "loss_fn = penalized_uncertainty(loss_criterion,np.log(10))\n",
    "\n",
    "model_trainer_1 = Trainer_with_g(model_1,optimizer,loss_fn, train_dataloader,validation_dataloader,c = 0.2)\n",
    "model_trainer_1.fit_all(train_dataloader,200)\n",
    "acc, g, bce = model_metrics(model_1,loss_criterion,train_dataloader)\n",
    "print('Conjunto de treinamento: acc = ', acc, 'média de g = ', g, 'média de bce = ', bce, '\\n')\n",
    "acc, g, bce = model_metrics(model_1,loss_criterion,test_dataloader)\n",
    "print('Conjunto de teste: acc = ', acc, 'média de g = ', g, 'média de bce = ', bce, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 , loss =  1.1922246829986571\n",
      "Epoch  1 , loss =  0.5212113477706909\n",
      "Epoch  1 , loss =  0.520684111738205\n",
      "Epoch  1 , loss =  0.5201988306045532\n",
      "Epoch  1 , loss =  0.5197402727603913\n",
      "Epoch  1 , loss =  0.5193021864891052\n",
      "Epoch  1 , loss =  0.5188841783046723\n",
      "Epoch  1 , loss =  0.5184836725234986\n",
      "Epoch  1 , loss =  0.5180991847991944\n",
      "Epoch  1 , loss =  0.5177333681583405\n",
      "Epoch  1 , loss =  0.5173823194980621\n",
      "Epoch  1 , loss =  0.5170460584163665\n",
      "Epoch  1 , loss =  0.5167211390018464\n",
      "Epoch  1 , loss =  0.5164075161933899\n",
      "Epoch  1 , loss =  0.5161055882453919\n",
      "Epoch  1 , loss =  0.5158129669189453\n",
      "Epoch  1 , loss =  0.5155284389972686\n",
      "Epoch  1 , loss =  0.5152503711223603\n",
      "Epoch  1 , loss =  0.5149815976142883\n",
      "Epoch  1 , loss =  0.5147210410118103\n",
      "Epoch  1 , loss =  0.514467029094696\n",
      "Epoch  1 , loss =  0.5142192105770111\n",
      "Epoch  1 , loss =  0.513979636144638\n",
      "Epoch  1 , loss =  0.5137450945854187\n",
      "Epoch  1 , loss =  0.5135151543140412\n",
      "Epoch  1 , loss =  0.5132906772136688\n",
      "Epoch  1 , loss =  0.513071199131012\n",
      "Epoch  1 , loss =  0.5128559930801392\n",
      "Epoch  1 , loss =  0.5126473595142365\n",
      "Epoch  1 , loss =  0.5124427805900573\n",
      "Epoch  1 , loss =  0.5122429425239563\n",
      "Epoch  1 , loss =  0.5120473503112793\n",
      "Epoch  1 , loss =  0.5118542982578278\n",
      "Epoch  1 , loss =  0.5116670693874359\n",
      "Epoch  1 , loss =  0.511481623506546\n",
      "Epoch  1 , loss =  0.5113009277820587\n",
      "Epoch  1 , loss =  0.5111249496936798\n",
      "Epoch  1 , loss =  0.5109511759281159\n",
      "Epoch  1 , loss =  0.5107809380054474\n",
      "Epoch  1 , loss =  0.5106123407840729\n",
      "Epoch  1 , loss =  0.5104476770401001\n",
      "Epoch  1 , loss =  0.5102865070819854\n",
      "Epoch  1 , loss =  0.510128961610794\n",
      "Epoch  1 , loss =  0.5099744450092316\n",
      "Epoch  1 , loss =  0.5098215100765229\n",
      "Epoch  1 , loss =  0.509671837902069\n",
      "Epoch  1 , loss =  0.5095256682395936\n",
      "Epoch  1 , loss =  0.5093827030181884\n",
      "Epoch  1 , loss =  0.5092415537834167\n",
      "Epoch  1 , loss =  0.5091024122238159\n",
      "Epoch  1 , loss =  0.508966686964035\n",
      "Epoch  1 , loss =  0.50883306889534\n",
      "Epoch  1 , loss =  0.5087030479907989\n",
      "Epoch  1 , loss =  0.5085733694076539\n",
      "Epoch  1 , loss =  0.5084471182346344\n",
      "Epoch  1 , loss =  0.5083229077816009\n",
      "Epoch  1 , loss =  0.5082006808757782\n",
      "Epoch  1 , loss =  0.5080799803256989\n",
      "Epoch  1 , loss =  0.5079616896152497\n",
      "Epoch  1 , loss =  0.5078452049732208\n",
      "Epoch  1 , loss =  0.5077307994842529\n",
      "Epoch  1 , loss =  0.5076181578159332\n",
      "Epoch  1 , loss =  0.5075070036411286\n",
      "Epoch  1 , loss =  0.5073971612930298\n",
      "Epoch  1 , loss =  0.507289410829544\n",
      "Epoch  1 , loss =  0.507183318567276\n",
      "Epoch  1 , loss =  0.507078816986084\n",
      "Epoch  1 , loss =  0.5069758428573609\n",
      "Epoch  1 , loss =  0.5068748340606689\n",
      "Epoch  1 , loss =  0.5067752898216248\n",
      "Epoch  1 , loss =  0.5066774295330048\n",
      "Epoch  1 , loss =  0.5065820467948914\n",
      "Epoch  1 , loss =  0.5064858704090118\n",
      "Epoch  1 , loss =  0.5063918566703797\n",
      "Epoch  1 , loss =  0.5062994644641876\n",
      "Epoch  1 , loss =  0.5062080822467804\n",
      "Epoch  1 , loss =  0.5061176006317138\n",
      "Epoch  1 , loss =  0.5060289933681488\n",
      "Epoch  1 , loss =  0.5059412623405457\n",
      "Epoch  1 , loss =  0.5058552049160003\n",
      "Epoch  1 , loss =  0.5057697068691254\n",
      "Epoch  1 , loss =  0.5056862886428833\n",
      "Epoch  1 , loss =  0.5056030901908874\n",
      "Epoch  1 , loss =  0.5055213352680207\n",
      "Epoch  1 , loss =  0.5054413896560669\n",
      "Epoch  1 , loss =  0.5053616969585418\n",
      "Epoch  1 , loss =  0.505282074213028\n",
      "Epoch  1 , loss =  0.5052042295932769\n",
      "Epoch  1 , loss =  0.5051275426387787\n",
      "Epoch  1 , loss =  0.5050505693435668\n",
      "Epoch  1 , loss =  0.5049755563735961\n",
      "Epoch  1 , loss =  0.5049021434783936\n",
      "Epoch  1 , loss =  0.5048275882720947\n",
      "Epoch  1 , loss =  0.5047559560775757\n",
      "Epoch  1 , loss =  0.504683099269867\n",
      "Epoch  1 , loss =  0.5046127539634705\n",
      "Epoch  1 , loss =  0.5045429406166076\n",
      "Epoch  1 , loss =  0.5044734926700593\n",
      "Epoch  1 , loss =  0.5044049559116364\n",
      "Epoch  1 , loss =  0.5043370973587036\n",
      "Epoch  1 , loss =  0.5042699774265289\n",
      "Epoch  1 , loss =  0.5042032067775726\n",
      "Epoch  1 , loss =  0.5041384227752685\n",
      "Epoch  1 , loss =  0.5040735447406769\n",
      "Epoch  1 , loss =  0.5040089262008667\n",
      "Epoch  1 , loss =  0.5039451810836793\n",
      "Epoch  1 , loss =  0.5038819208145141\n",
      "Epoch  1 , loss =  0.5038209523677826\n",
      "Epoch  1 , loss =  0.5037587554931641\n",
      "Epoch  1 , loss =  0.5036976932525635\n",
      "Epoch  1 , loss =  0.5036381421089172\n",
      "Epoch  1 , loss =  0.503577495098114\n",
      "Epoch  1 , loss =  0.503518860912323\n",
      "Epoch  1 , loss =  0.5034595647811889\n",
      "Epoch  1 , loss =  0.5034024389266968\n",
      "Epoch  1 , loss =  0.5033441608905792\n",
      "Epoch  1 , loss =  0.5032877883911133\n",
      "Epoch  1 , loss =  0.503231214761734\n",
      "Epoch  1 , loss =  0.5031751896858215\n",
      "Epoch  1 , loss =  0.503120656299591\n",
      "Epoch  1 , loss =  0.5030650150299072\n",
      "Epoch  1 , loss =  0.5030117339611053\n",
      "Epoch  1 , loss =  0.5029584067821503\n",
      "Epoch  1 , loss =  0.5029052286148071\n",
      "Epoch  1 , loss =  0.5028523845672608\n",
      "Epoch  1 , loss =  0.5028011778831482\n",
      "Epoch  1 , loss =  0.5027499482631683\n",
      "Epoch  1 , loss =  0.5026981595516204\n",
      "Epoch  1 , loss =  0.5026478043556213\n",
      "Epoch  1 , loss =  0.5025970976829529\n",
      "Epoch  1 , loss =  0.5025481407642365\n",
      "Epoch  1 , loss =  0.502499350309372\n",
      "Epoch  1 , loss =  0.502449077796936\n",
      "Epoch  1 , loss =  0.5024018912792206\n",
      "Epoch  1 , loss =  0.5023540039539337\n",
      "Epoch  1 , loss =  0.5023068074226379\n",
      "Epoch  1 , loss =  0.5022599040985107\n",
      "Epoch  1 , loss =  0.5022129544734955\n",
      "Epoch  1 , loss =  0.5021669050693512\n",
      "Epoch  1 , loss =  0.502121729183197\n",
      "Epoch  1 , loss =  0.502076589345932\n",
      "Epoch  1 , loss =  0.5020322435379029\n",
      "Epoch  1 , loss =  0.5019886002540589\n",
      "Epoch  1 , loss =  0.5019438356399536\n",
      "Epoch  1 , loss =  0.5019007225036621\n",
      "Epoch  1 , loss =  0.501856740140915\n",
      "Epoch  1 , loss =  0.5018149363517761\n",
      "Epoch  1 , loss =  0.5017722751617432\n",
      "Epoch  1 , loss =  0.5017294249534607\n",
      "Epoch  1 , loss =  0.5016897367477418\n",
      "Epoch  1 , loss =  0.5016472736358643\n",
      "Epoch  1 , loss =  0.5016074759483338\n",
      "Epoch  1 , loss =  0.501566996383667\n",
      "Epoch  1 , loss =  0.5015272353172302\n",
      "Epoch  1 , loss =  0.5014884437561035\n",
      "Epoch  1 , loss =  0.5014484063625335\n",
      "Epoch  1 , loss =  0.5014094905376434\n",
      "Epoch  1 , loss =  0.5013712617397308\n",
      "Epoch  1 , loss =  0.5013332129001618\n",
      "Epoch  1 , loss =  0.501294449186325\n",
      "Epoch  1 , loss =  0.5012561640739441\n",
      "Epoch  1 , loss =  0.5012192808628082\n",
      "Epoch  1 , loss =  0.501182015800476\n",
      "Epoch  1 , loss =  0.5011454062461853\n",
      "Epoch  1 , loss =  0.5011082473754883\n",
      "Epoch  1 , loss =  0.501071788930893\n",
      "Epoch  1 , loss =  0.5010357967853546\n",
      "Epoch  1 , loss =  0.5009998710155487\n",
      "Epoch  1 , loss =  0.5009641655445098\n",
      "Epoch  1 , loss =  0.5009302203655243\n",
      "Epoch  1 , loss =  0.5008949388504028\n",
      "Epoch  1 , loss =  0.5008600935935974\n",
      "Epoch  1 , loss =  0.5008262842655182\n",
      "Epoch  1 , loss =  0.5007924018859863\n",
      "Epoch  1 , loss =  0.5007590476036072\n",
      "Epoch  1 , loss =  0.5007259013652802\n",
      "Epoch  1 , loss =  0.5006923008918762\n",
      "Epoch  1 , loss =  0.5006585776805877\n",
      "Epoch  1 , loss =  0.5006266256332398\n",
      "Epoch  1 , loss =  0.500593976688385\n",
      "Epoch  1 , loss =  0.5005624156475067\n",
      "Epoch  1 , loss =  0.5005301091194153\n",
      "Epoch  1 , loss =  0.5004988016605377\n",
      "Epoch  1 , loss =  0.5004669958591461\n",
      "Epoch  1 , loss =  0.5004356211185456\n",
      "Epoch  1 , loss =  0.5004050026893616\n",
      "Epoch  1 , loss =  0.5003744607448578\n",
      "Epoch  1 , loss =  0.5003432472229004\n",
      "Epoch  1 , loss =  0.5003138760089875\n",
      "Epoch  1 , loss =  0.5002834180355072\n",
      "Epoch  1 , loss =  0.5002534954547883\n",
      "Epoch  1 , loss =  0.5002247520446778\n",
      "Epoch  1 , loss =  0.5001960651874542\n",
      "Epoch  1 , loss =  0.5001663175582886\n",
      "Epoch  1 , loss =  0.5001375686168671\n",
      "Epoch  1 , loss =  0.5001091951847076\n",
      "Epoch  1 , loss =  0.5000810703277588\n",
      "Epoch  1 , loss =  0.5000528706550598\n",
      "Epoch  1 , loss =  0.5000242424011231\n",
      "Epoch  1 , loss =  0.49999706091880797\n",
      "Conjunto de treinamento: acc =  0.10049411764705882 média de g =  0.10209216730734881 média de bce =  2.3288065203498394 \n",
      "\n",
      "Conjunto de teste: acc =  0.0959 média de g =  0.10210159730911254 média de bce =  2.3310886169433593 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_sep = Model_CNN_with_g()\n",
    "model_sep = model_sep.to(dev)\n",
    "model_sep.load_state_dict(state_dict,strict = False)\n",
    "optimizer = torch.optim.SGD(model_sep.parameters(), lr=1e-3)\n",
    "loss_criterion = nn.NLLLoss(reduction = 'none')\n",
    "loss_fn = penalized_uncertainty(loss_criterion,np.log(10))\n",
    "\n",
    "model_trainer_sep = Trainer_with_g(model_sep,optimizer,loss_fn, train_dataloader,validation_dataloader,c = 0.2)\n",
    "model_trainer_sep.hist_train = model_trainer.hist_train\n",
    "model_trainer_sep.hist_val = model_trainer.hist_val\n",
    "model_trainer_sep.hist_val.c = 0.2\n",
    "\n",
    "#model_trainer_sep.fit(train_dataloader,40)\n",
    "#model_trainer_sep.optimizer = torch.optim.SGD(model_sep.parameters(), lr=1e-2) #testar variações de lr\n",
    "model_trainer_sep.fit_g(validation_dataloader,200)\n",
    "\n",
    "acc, g, bce = model_metrics(model_sep,loss_criterion,train_dataloader)\n",
    "print('Conjunto de treinamento: acc = ', acc, 'média de g = ', g, 'média de bce = ', bce, '\\n')\n",
    "acc, g, bce = model_metrics(model_sep,loss_criterion,test_dataloader)\n",
    "print('Conjunto de teste: acc = ', acc, 'média de g = ', g, 'média de bce = ', bce, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 , loss =  2.127191789671232\n",
      "Epoch  1 , loss =  1.6735845494748238\n",
      "Epoch  1 , loss =  1.4710401970743796\n",
      "Epoch  1 , loss =  1.3494695694617536\n",
      "Epoch  1 , loss =  1.2341767882876717\n",
      "Epoch  1 , loss =  1.1163182905641134\n",
      "Epoch  1 , loss =  1.1269351798454157\n",
      "Epoch  1 , loss =  1.0452796544128726\n",
      "Epoch  1 , loss =  1.0293637551809016\n",
      "Epoch  1 , loss =  1.0198743759845355\n",
      "Epoch  1 , loss =  1.0063617422983244\n",
      "Epoch  1 , loss =  0.9414404416020343\n",
      "Epoch  1 , loss =  0.9235521502696075\n",
      "Epoch  1 , loss =  0.9403438057638979\n",
      "Epoch  1 , loss =  0.8773932461597904\n",
      "Epoch  1 , loss =  0.8708647974108923\n",
      "Epoch  1 , loss =  0.8496400562973766\n",
      "Epoch  1 , loss =  0.8099564119020739\n",
      "Epoch  1 , loss =  0.8564803261143686\n",
      "Epoch  1 , loss =  0.7804034991386515\n",
      "Epoch  1 , loss =  0.7698184375639086\n",
      "Epoch  1 , loss =  0.7552894829088251\n",
      "Epoch  1 , loss =  0.7433077110990436\n",
      "Epoch  1 , loss =  0.6959693164457916\n",
      "Epoch  1 , loss =  0.7153422968374814\n",
      "Epoch  1 , loss =  0.6715912522820683\n",
      "Epoch  1 , loss =  0.6413680922002324\n",
      "Epoch  1 , loss =  0.6642488553396462\n",
      "Epoch  1 , loss =  0.6788333000048347\n",
      "Epoch  1 , loss =  0.5929744957506085\n",
      "Epoch  1 , loss =  0.6030731502897251\n",
      "Epoch  1 , loss =  0.5844304520554761\n",
      "Epoch  1 , loss =  0.5516033008703063\n",
      "Epoch  1 , loss =  0.5585752786644632\n",
      "Epoch  1 , loss =  0.5553109607055051\n",
      "Epoch  1 , loss =  0.5121744225660937\n",
      "Epoch  1 , loss =  0.5302618723373201\n",
      "Epoch  1 , loss =  0.5161794646733027\n",
      "Epoch  1 , loss =  0.495373454643282\n",
      "Epoch  1 , loss =  0.5152772737804744\n",
      "Epoch  1 , loss =  0.47862304710714176\n",
      "Epoch  1 , loss =  0.47130819517153594\n",
      "Epoch  1 , loss =  0.46425843262757827\n",
      "Epoch  1 , loss =  0.46059159126988847\n",
      "Epoch  1 , loss =  0.5652135961043808\n",
      "Epoch  1 , loss =  0.4519849161957698\n",
      "Epoch  1 , loss =  0.46663473682180423\n",
      "Epoch  1 , loss =  0.43423820440544375\n",
      "Epoch  1 , loss =  0.4709976090608403\n",
      "Epoch  1 , loss =  0.47334199191929843\n",
      "Epoch  1 , loss =  0.40164879175509893\n",
      "Epoch  1 , loss =  0.42284814162965484\n",
      "Epoch  1 , loss =  0.395677709421916\n",
      "Epoch  1 , loss =  0.4181541250498028\n",
      "Epoch  1 , loss =  0.4061373363736489\n",
      "Epoch  1 , loss =  0.44371758584739807\n",
      "Epoch  1 , loss =  0.3887428424259588\n",
      "Epoch  1 , loss =  0.3778993286437474\n",
      "Epoch  1 , loss =  0.3892590304952849\n",
      "Epoch  1 , loss =  0.3787106093984751\n",
      "Epoch  1 , loss =  0.3827626529042696\n",
      "Epoch  1 , loss =  0.3704751626809797\n",
      "Epoch  1 , loss =  0.3696565008861602\n",
      "Epoch  1 , loss =  0.36753594577322984\n",
      "Epoch  1 , loss =  0.3674813446818621\n",
      "Epoch  1 , loss =  0.3569986678045695\n",
      "Epoch  1 , loss =  0.3526065934006123\n",
      "Epoch  1 , loss =  0.35010743090322316\n",
      "Epoch  1 , loss =  0.33489377875787374\n",
      "Epoch  1 , loss =  0.3378256544579117\n",
      "Epoch  1 , loss =  0.3502524894566673\n",
      "Epoch  1 , loss =  0.3292821136995822\n",
      "Epoch  1 , loss =  0.331850775194571\n",
      "Epoch  1 , loss =  0.35097144033685157\n",
      "Epoch  1 , loss =  0.319389927041699\n",
      "Epoch  1 , loss =  0.3353651065156805\n",
      "Epoch  1 , loss =  0.3174985140026455\n",
      "Epoch  1 , loss =  0.31035101315631614\n",
      "Epoch  1 , loss =  0.30379025430896045\n",
      "Epoch  1 , loss =  0.3126463452611752\n",
      "Conjunto de treinamento: acc =  0.7897647058823529 média de g =  0.6164513831867892 média de bce =  0.6764206659281955 \n",
      "\n",
      "Conjunto de teste: acc =  0.6765 média de g =  0.6216127178192139 média de bce =  1.1154713142395019 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_2 = Model_CNN_with_g_2()\n",
    "model_2 = model_2.to(dev)\n",
    "optimizer = torch.optim.SGD(model_2.parameters(), lr=1e-3)\n",
    "loss_criterion = nn.NLLLoss(reduction = 'none')\n",
    "loss_fn = penalized_uncertainty(loss_criterion,np.log(10))\n",
    "\n",
    "model_trainer_2 = Trainer_with_g(model_2,optimizer,loss_fn, train_dataloader,validation_dataloader,c = 0.2)\n",
    "model_trainer_2.fit_all(train_dataloader,80)\n",
    "\n",
    "acc, g, bce = model_metrics(model_2,loss_criterion,train_dataloader)\n",
    "print('Conjunto de treinamento: acc = ', acc, 'média de g = ', g, 'média de bce = ', bce, '\\n')\n",
    "acc, g, bce = model_metrics(model_2,loss_criterion,test_dataloader)\n",
    "print('Conjunto de teste: acc = ', acc, 'média de g = ', g, 'média de bce = ', bce, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 , loss =  0.2968389642067813\n",
      "Epoch  1 , loss =  0.29070024498181446\n",
      "Epoch  1 , loss =  0.27099289209857996\n",
      "Epoch  1 , loss =  0.2517227002249674\n",
      "Epoch  1 , loss =  0.2441359755747706\n",
      "Epoch  1 , loss =  0.23955971370059376\n",
      "Epoch  1 , loss =  0.23644097687025517\n",
      "Epoch  1 , loss =  0.23402158949862828\n",
      "Epoch  1 , loss =  0.23205034803748467\n",
      "Epoch  1 , loss =  0.23040675888293413\n",
      "Epoch  1 , loss =  0.22901517063387702\n",
      "Epoch  1 , loss =  0.2278246636897376\n",
      "Epoch  1 , loss =  0.22677750012115325\n",
      "Epoch  1 , loss =  0.22579026433840638\n",
      "Epoch  1 , loss =  0.22498861181995142\n",
      "Epoch  1 , loss =  0.2242322897571147\n",
      "Epoch  1 , loss =  0.22351822954350645\n",
      "Epoch  1 , loss =  0.22286475645215212\n",
      "Epoch  1 , loss =  0.22224894637491224\n",
      "Epoch  1 , loss =  0.2216745160019445\n",
      "Epoch  1 , loss =  0.22118211413282987\n",
      "Epoch  1 , loss =  0.2206257650074415\n",
      "Epoch  1 , loss =  0.2201557231037328\n",
      "Epoch  1 , loss =  0.21967617805599157\n",
      "Epoch  1 , loss =  0.21924772803192588\n",
      "Epoch  1 , loss =  0.21880281610568994\n",
      "Epoch  1 , loss =  0.2183984621858644\n",
      "Epoch  1 , loss =  0.21798818266279008\n",
      "Epoch  1 , loss =  0.2176315351912593\n",
      "Epoch  1 , loss =  0.21724865762259177\n",
      "Epoch  1 , loss =  0.2168235676273712\n",
      "Epoch  1 , loss =  0.21652873824358423\n",
      "Epoch  1 , loss =  0.2161857122497529\n",
      "Epoch  1 , loss =  0.21581728089199034\n",
      "Epoch  1 , loss =  0.21554573668027113\n",
      "Epoch  1 , loss =  0.21522291676198643\n",
      "Epoch  1 , loss =  0.2148500644469887\n",
      "Epoch  1 , loss =  0.21456096547470127\n",
      "Epoch  1 , loss =  0.21425353901651134\n",
      "Epoch  1 , loss =  0.21392576158559976\n",
      "Epoch  1 , loss =  0.2136442176387648\n",
      "Epoch  1 , loss =  0.21335093453021658\n",
      "Epoch  1 , loss =  0.2130401903823363\n",
      "Epoch  1 , loss =  0.2127168569072265\n",
      "Epoch  1 , loss =  0.21240106656019933\n",
      "Epoch  1 , loss =  0.21211457388177893\n",
      "Epoch  1 , loss =  0.21182476188240754\n",
      "Epoch  1 , loss =  0.21150753700517788\n",
      "Epoch  1 , loss =  0.21117779615906793\n",
      "Epoch  1 , loss =  0.2108824175589506\n",
      "Epoch  1 , loss =  0.21054633963013827\n",
      "Epoch  1 , loss =  0.21022677686925764\n",
      "Epoch  1 , loss =  0.20984624092846285\n",
      "Epoch  1 , loss =  0.20947440088274855\n",
      "Epoch  1 , loss =  0.20908609992876556\n",
      "Epoch  1 , loss =  0.20863679854513764\n",
      "Epoch  1 , loss =  0.20817195852237155\n",
      "Epoch  1 , loss =  0.20761217492438522\n",
      "Epoch  1 , loss =  0.20698511579301668\n",
      "Epoch  1 , loss =  0.20624591257130775\n",
      "Epoch  1 , loss =  0.20558147975267294\n",
      "Epoch  1 , loss =  0.20487148780007608\n",
      "Epoch  1 , loss =  0.20423956044998498\n",
      "Epoch  1 , loss =  0.20359422945807137\n",
      "Epoch  1 , loss =  0.20294095451913602\n",
      "Epoch  1 , loss =  0.20231546719891416\n",
      "Epoch  1 , loss =  0.20169410270963228\n",
      "Epoch  1 , loss =  0.20107888946449567\n",
      "Epoch  1 , loss =  0.20046604317857478\n",
      "Epoch  1 , loss =  0.1998323802449722\n",
      "Epoch  1 , loss =  0.19919957777034053\n",
      "Epoch  1 , loss =  0.19854607371343083\n",
      "Epoch  1 , loss =  0.19796535018610625\n",
      "Epoch  1 , loss =  0.19735151333266365\n",
      "Epoch  1 , loss =  0.19671192588121592\n",
      "Epoch  1 , loss =  0.1961373982163286\n",
      "Epoch  1 , loss =  0.19552955623318555\n",
      "Epoch  1 , loss =  0.19491667724317038\n",
      "Epoch  1 , loss =  0.1943010610671854\n",
      "Epoch  1 , loss =  0.19362767213952367\n",
      "Epoch  1 , loss =  0.19302867696463288\n",
      "Epoch  1 , loss =  0.19239677028401314\n",
      "Epoch  1 , loss =  0.19175481813828835\n",
      "Epoch  1 , loss =  0.19111402608971687\n",
      "Epoch  1 , loss =  0.1904619688705611\n",
      "Epoch  1 , loss =  0.1898575112494976\n",
      "Epoch  1 , loss =  0.18925837184423985\n",
      "Epoch  1 , loss =  0.18864946506963753\n",
      "Epoch  1 , loss =  0.18803879678909857\n",
      "Epoch  1 , loss =  0.1874481473267415\n",
      "Epoch  1 , loss =  0.1868768435629965\n",
      "Epoch  1 , loss =  0.18632867591553393\n",
      "Epoch  1 , loss =  0.18580395788088955\n",
      "Epoch  1 , loss =  0.18527287192630068\n",
      "Epoch  1 , loss =  0.18473547930029374\n",
      "Epoch  1 , loss =  0.18419888100777723\n",
      "Epoch  1 , loss =  0.18374511624151607\n",
      "Epoch  1 , loss =  0.18325287886258407\n",
      "Epoch  1 , loss =  0.18287703274990597\n",
      "Epoch  1 , loss =  0.18241633780149166\n",
      "Epoch  1 , loss =  0.18199428627693437\n",
      "Epoch  1 , loss =  0.18162725847856026\n",
      "Epoch  1 , loss =  0.18130802808467242\n",
      "Epoch  1 , loss =  0.1809301659494285\n",
      "Epoch  1 , loss =  0.18062367705593568\n",
      "Epoch  1 , loss =  0.18026576879135064\n",
      "Epoch  1 , loss =  0.1799708852614894\n",
      "Epoch  1 , loss =  0.1796629057249516\n",
      "Epoch  1 , loss =  0.179389983939374\n",
      "Epoch  1 , loss =  0.17910612273155666\n",
      "Epoch  1 , loss =  0.17881359933822388\n",
      "Epoch  1 , loss =  0.17853886764422944\n",
      "Epoch  1 , loss =  0.17830471663758418\n",
      "Epoch  1 , loss =  0.17805861262157602\n",
      "Epoch  1 , loss =  0.17777336822199002\n",
      "Epoch  1 , loss =  0.17758252274693068\n",
      "Epoch  1 , loss =  0.17734405432971334\n",
      "Epoch  1 , loss =  0.17711840474211366\n",
      "Epoch  1 , loss =  0.1769279707601806\n",
      "Epoch  1 , loss =  0.17667425058693753\n",
      "Epoch  1 , loss =  0.17646577765924287\n",
      "Epoch  1 , loss =  0.17631926194342398\n",
      "Epoch  1 , loss =  0.17610041521077335\n",
      "Epoch  1 , loss =  0.17591175477150334\n",
      "Epoch  1 , loss =  0.1756896053523431\n",
      "Epoch  1 , loss =  0.17556924677707933\n",
      "Epoch  1 , loss =  0.1753253037281406\n",
      "Epoch  1 , loss =  0.1752050854686389\n",
      "Epoch  1 , loss =  0.17501654877800144\n",
      "Epoch  1 , loss =  0.17486751610797083\n",
      "Epoch  1 , loss =  0.17470684956037716\n",
      "Epoch  1 , loss =  0.17457293722944736\n"
     ]
    }
   ],
   "source": [
    "#modelo 2 # testar com tanh\n",
    "model_sep_2 = Model_CNN_with_g_2()\n",
    "model_sep_2 = model_sep_2.to(dev)\n",
    "model_sep_2.load_state_dict(state_dict,strict = False)\n",
    "optimizer = torch.optim.SGD(model_sep_2.parameters(), lr=1e-3)\n",
    "loss_criterion = nn.NLLLoss(reduction = 'none')\n",
    "loss_fn = penalized_uncertainty(loss_criterion,np.log(10))\n",
    "\n",
    "model_trainer_sep_2 = Trainer_with_g(model_sep_2,optimizer,loss_fn, train_dataloader,validation_dataloader,c = 0.2)\n",
    "model_trainer_sep_2.hist_train.acc_list = copy.copy(model_trainer.hist_train.acc_list)\n",
    "model_trainer_sep_2.hist_train.loss_list = copy.copy(model_trainer.hist_train.loss_list)\n",
    "model_trainer_sep_2.hist_val.acc_list = copy.copy(model_trainer.hist_val.acc_list)\n",
    "model_trainer_sep_2.hist_val.loss_list = copy.copy(model_trainer.hist_val.loss_list)\n",
    "#model_trainer_sep_2.fit(train_dataloader,40)\n",
    "model_trainer_sep_2.fit_g(train_dataloader,200)\n",
    "\n",
    "acc, g, bce = model_metrics(model_sep_2,loss_criterion,train_dataloader)\n",
    "print('Conjunto de treinamento: acc = ', acc, 'média de g = ', g, 'média de bce = ', bce, '\\n')\n",
    "acc, g, bce = model_metrics(model_sep_2,loss_criterion,test_dataloader)\n",
    "print('Conjunto de teste: acc = ', acc, 'média de g = ', g, 'média de bce = ', bce, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = Model_CNN_with_g_3()\n",
    "model_3 = model_3.to(dev)\n",
    "optimizer = torch.optim.SGD(model_3.parameters(), lr=1e-3)\n",
    "loss_criterion = nn.NLLLoss(reduction = 'none')\n",
    "loss_fn = penalized_uncertainty(loss_criterion,np.log(10))\n",
    "\n",
    "model_trainer_3 = Trainer_with_g(model_3,optimizer,loss_fn, train_dataloader,validation_dataloader,c = 0.2)\n",
    "model_trainer_3.fit_all(train_dataloader,80)\n",
    "\n",
    "acc, g, bce = model_metrics(model_3,loss_criterion,train_dataloader)\n",
    "print('Conjunto de treinamento: acc = ', acc, 'média de g = ', g, 'média de bce = ', bce, '\\n')\n",
    "acc, g, bce = model_metrics(model_3,loss_criterion,test_dataloader)\n",
    "print('Conjunto de teste: acc = ', acc, 'média de g = ', g, 'média de bce = ', bce, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelo 3\n",
    "model_sep_3 = Model_CNN_with_g_3()\n",
    "model_sep_3 = model_sep_3.to(dev)\n",
    "model_sep_3.load_state_dict(state_dict,strict = False)\n",
    "optimizer = torch.optim.SGD(model_sep_3.parameters(), lr=1e-3)\n",
    "loss_criterion = nn.NLLLoss(reduction = 'none')\n",
    "loss_fn = penalized_uncertainty(loss_criterion,np.log(10))\n",
    "\n",
    "model_trainer_sep_3 = Trainer_with_g(model_sep_3,optimizer,loss_fn, train_dataloader,validation_dataloader,c = 0.2)\n",
    "model_trainer_sep_3.hist_train.acc_list = copy.copy(model_trainer.hist_train.acc_list)\n",
    "model_trainer_sep_3.hist_train.loss_list = copy.copy(model_trainer.hist_train.loss_list)\n",
    "model_trainer_sep_3.hist_val.acc_list = copy.copy(model_trainer.hist_val.acc_list)\n",
    "model_trainer_sep_3.hist_val.loss_list = copy.copy(model_trainer.hist_val.loss_list)\n",
    "#model_trainer_sep_2.fit(train_dataloader,40)\n",
    "model_trainer_sep_3.fit_g(train_dataloader,200)\n",
    "\n",
    "acc, g, bce = model_metrics(model_sep_3,loss_criterion,train_dataloader)\n",
    "print('Conjunto de treinamento: acc = ', acc, 'média de g = ', g, 'média de bce = ', bce, '\\n')\n",
    "acc, g, bce = model_metrics(model_sep_3,loss_criterion,test_dataloader)\n",
    "print('Conjunto de teste: acc = ', acc, 'média de g = ', g, 'média de bce = ', bce, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4 = Model_CNN_with_g_4()\n",
    "model_4 = model_4.to(dev)\n",
    "optimizer = torch.optim.SGD(model_4.parameters(), lr=1e-3)\n",
    "loss_criterion = nn.NLLLoss(reduction = 'none')\n",
    "loss_fn = penalized_uncertainty(loss_criterion,np.log(10))\n",
    "\n",
    "model_trainer_4 = Trainer_with_g(model_4,optimizer,loss_fn, train_dataloader,validation_dataloader,c = 0.2)\n",
    "model_trainer_4.fit_all(train_dataloader,80)\n",
    "\n",
    "acc, g, bce = model_metrics(model_4,loss_criterion,train_dataloader)\n",
    "print('Conjunto de treinamento: acc = ', acc, 'média de g = ', g, 'média de bce = ', bce, '\\n')\n",
    "acc, g, bce = model_metrics(model_4,loss_criterion,test_dataloader)\n",
    "print('Conjunto de teste: acc = ', acc, 'média de g = ', g, 'média de bce = ', bce, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelo 2\n",
    "model_sep_4 = Model_CNN_with_g_4()\n",
    "model_sep_4 = model_sep_4.to(dev)\n",
    "model_sep_4.load_state_dict(state_dict,strict = False)\n",
    "optimizer = torch.optim.SGD(model_sep_4.parameters(), lr=1e-3)\n",
    "loss_criterion = nn.NLLLoss(reduction = 'none')\n",
    "loss_fn = penalized_uncertainty(loss_criterion,np.log(10))\n",
    "\n",
    "model_trainer_sep_4 = Trainer_with_g(model_sep_4,optimizer,loss_fn, train_dataloader,validation_dataloader,c = 0.2)\n",
    "model_trainer_sep_4.hist_train.acc_list = model_trainer.hist_train.acc_list\n",
    "model_trainer_sep_4.hist_train.loss_list = model_trainer.hist_train.loss_list\n",
    "model_trainer_sep_4.hist_val.acc_list = model_trainer.hist_val.acc_list\n",
    "model_trainer_sep_4.hist_val.loss_list = model_trainer.hist_val.loss_list\n",
    "#model_trainer_sep_2.fit(train_dataloader,40)\n",
    "model_trainer_sep_4.fit_g(train_dataloader,200)\n",
    "\n",
    "acc, g, bce = model_metrics(model_sep_4,loss_criterion,train_dataloader)\n",
    "print('Conjunto de treinamento: acc = ', acc, 'média de g = ', g, 'média de bce = ', bce, '\\n')\n",
    "acc, g, bce = model_metrics(model_sep_4,loss_criterion,test_dataloader)\n",
    "print('Conjunto de teste: acc = ', acc, 'média de g = ', g, 'média de bce = ', bce, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "#### Perda adaptada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelo 2\n",
    "model_sep_mcp = Model_CNN_with_g_2()\n",
    "model_sep_mcp = model_sep_mcp.to(dev)\n",
    "optimizer = torch.optim.SGD(model_sep_mcp.parameters(), lr=1e-3)\n",
    "loss_fn = aux_loss(loss_criterion)#penalized_uncertainty(loss_criterion,np.log(10))\n",
    "\n",
    "model_trainer_sep_mcp = Trainer_with_g(model_sep_mcp,optimizer,loss_fn, train_dataloader,validation_dataloader,c = 0.2)\n",
    "model_trainer_sep_mcp.fit(train_dataloader,40)\n",
    "model_trainer_sep_mcp.fit_g(validation_dataloader,200)\n",
    "\n",
    "acc, g, bce = model_metrics(model_sep_mcp,loss_criterion,train_dataloader)\n",
    "print('Conjunto de treinamento: acc = ', acc, 'média de g = ', g, 'média de bce = ', bce, '\\n')\n",
    "acc, g, bce = model_metrics(model_sep_mcp,loss_criterion,test_dataloader)\n",
    "print('Conjunto de teste: acc = ', acc, 'média de g = ', g, 'média de bce = ', bce, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelo fs\n",
    "'''model_sep_fs = Model_CNN_with_g_2()\n",
    "model_sep_fs = model_sep_fs.to(dev)\n",
    "model_sep_fs.load_state_dict(state_dict,strict = False)\n",
    "optimizer = torch.optim.SGD(model_sep_fs.parameters(), lr=1e-3)\n",
    "loss_criterion = nn.NLLLoss(reduction = 'none')\n",
    "loss_fn = aux_loss_fs(loss_criterion)#penalized_uncertainty(loss_criterion,np.log(10))\n",
    "\n",
    "model_trainer_sep_fs = Trainer_with_g(model_sep_fs,optimizer,loss_fn, train_dataloader,validation_dataloader,c = 0.2)\n",
    "#model_trainer_sep_fs.fit(train_dataloader,40)\n",
    "model_trainer_sep_fs.hist_train.acc_list = copy.copy(model_trainer.hist_train.acc_list)\n",
    "model_trainer_sep_fs.hist_train.loss_list = copy.copy(model_trainer.hist_train.loss_list)\n",
    "model_trainer_sep_fs.hist_val.acc_list = copy.copy(model_trainer.hist_val.acc_list)\n",
    "model_trainer_sep_fs.hist_val.loss_list = copy.copy(model_trainer.hist_val.loss_list)'''\n",
    "\n",
    "model_trainer_sep_fs.loss_fn.criterion = nn.BCELoss()\n",
    "model_trainer_sep_fs.fit_g(train_dataloader,200)\n",
    "\n",
    "acc, g, bce = model_metrics(model_sep_fs,loss_criterion,train_dataloader)\n",
    "print('Conjunto de treinamento: acc = ', acc, 'média de g = ', g, 'média de bce = ', bce, '\\n')\n",
    "acc, g, bce = model_metrics(model_sep_fs,loss_criterion,test_dataloader)\n",
    "print('Conjunto de teste: acc = ', acc, 'média de g = ', g, 'média de bce = ', bce, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelo fs\n",
    "model_sep_fs_3 = Model_CNN_with_g_3()\n",
    "model_sep_fs_3 = model_sep_fs_3.to(dev)\n",
    "model_sep_fs_3.load_state_dict(state_dict,strict = False)\n",
    "optimizer = torch.optim.SGD(model_sep_fs_3.parameters(), lr=1e-3)\n",
    "loss_criterion = nn.NLLLoss(reduction = 'none')\n",
    "loss_fn = aux_loss_fs(loss_criterion)#penalized_uncertainty(loss_criterion,np.log(10))\n",
    "\n",
    "model_trainer_sep_fs_3 = Trainer_with_g(model_sep_fs_3,optimizer,loss_fn, train_dataloader,validation_dataloader,c = 0.2)\n",
    "#model_trainer_sep_fs.fit(train_dataloader,40)\n",
    "model_trainer_sep_fs_3.hist_train.acc_list = copy.copy(model_trainer.hist_train.acc_list)\n",
    "model_trainer_sep_fs_3.hist_train.loss_list = copy.copy(model_trainer.hist_train.loss_list)\n",
    "model_trainer_sep_fs_3.hist_val.acc_list = copy.copy(model_trainer.hist_val.acc_list)\n",
    "model_trainer_sep_fs_3.hist_val.loss_list = copy.copy(model_trainer.hist_val.loss_list)\n",
    "\n",
    "model_trainer_sep_fs_3.loss_fn.criterion = nn.BCELoss()\n",
    "model_trainer_sep_fs_3.fit_g(train_dataloader,800)\n",
    "\n",
    "acc, g, bce = model_metrics(model_sep_fs_3,loss_criterion,train_dataloader)\n",
    "print('Conjunto de treinamento: acc = ', acc, 'média de g = ', g, 'média de bce = ', bce, '\\n')\n",
    "acc, g, bce = model_metrics(model_sep_fs_3,loss_criterion,test_dataloader)\n",
    "print('Conjunto de teste: acc = ', acc, 'média de g = ', g, 'média de bce = ', bce, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelo fs\n",
    "model_sep_fs_4 = Model_CNN_with_g_4()\n",
    "model_sep_fs_4 = model_sep_fs_4.to(dev)\n",
    "model_sep_fs_4.load_state_dict(state_dict,strict = False)\n",
    "optimizer = torch.optim.SGD(model_sep_fs_4.parameters(), lr=1e-3)\n",
    "loss_criterion = nn.NLLLoss(reduction = 'none')\n",
    "loss_fn = aux_loss_fs(loss_criterion)#penalized_uncertainty(loss_criterion,np.log(10))\n",
    "\n",
    "model_trainer_sep_fs_4 = Trainer_with_g(model_sep_fs_4,optimizer,loss_fn, train_dataloader,validation_dataloader,c = 0.2)\n",
    "#model_trainer_sep_fs.fit(train_dataloader,40)\n",
    "model_trainer_sep_fs_4.hist_train.acc_list = model_trainer.hist_train.acc_list\n",
    "model_trainer_sep_fs_4.hist_train.loss_list = model_trainer.hist_train.loss_list\n",
    "model_trainer_sep_fs_4.hist_val.acc_list = model_trainer.hist_val.acc_list\n",
    "model_trainer_sep_fs_4.hist_val.loss_list = model_trainer.hist_val.loss_list\n",
    "\n",
    "model_trainer_sep_fs_4.loss_fn.criterion = nn.BCELoss()\n",
    "model_trainer_sep_fs_4.fit_g(train_dataloader,800)\n",
    "\n",
    "acc, g, bce = model_metrics(model_sep_fs,loss_criterion,train_dataloader)\n",
    "print('Conjunto de treinamento: acc = ', acc, 'média de g = ', g, 'média de bce = ', bce, '\\n')\n",
    "acc, g, bce = model_metrics(model_sep_fs,loss_criterion,test_dataloader)\n",
    "print('Conjunto de teste: acc = ', acc, 'média de g = ', g, 'média de bce = ', bce, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots e análises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {model:model_trainer,\n",
    "          model_sep_2:model_trainer_sep_2,\n",
    "          model_sep_4:model_trainer_sep_4,\n",
    "          model_sep_fs:model_trainer_sep_fs,\n",
    "          model_sep_fs_3:model_trainer_sep_fs_3,\n",
    "          model_sep_fs_4:model_trainer_sep_fs_4,\n",
    "          model_sep_3:model_trainer_sep_3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {model:model_trainer,\n",
    "          model_sep:model_trainer_sep,\n",
    "          model_2:model_trainer_2,\n",
    "          model_sep_2:model_trainer_sep_2#,\n",
    "          model_sep_22:model_trainer_sep_22,\n",
    "          model_sep_mcp:model_trainer_sep_mcp,\n",
    "          model_sep_fs:model_trainer_sep_fs,\n",
    "          model_3:model_trainer_3,\n",
    "          model_sep_3:model_trainer_sep_3,\n",
    "          model_sep_fs_3:model_trainer_sep_fs_3,\n",
    "          model_sep_32:model_trainer_sep_32,\n",
    "          model_sep_4:model_trainer_sep_4,\n",
    "          model_sep_fs_4:model_trainer_sep_fs_4}#,\n",
    "          model_4:model_trainer_4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = model\n",
    "trainer = models[mod]\n",
    "plt.plot(trainer.hist_train.acc_list, label = 'g - train')\n",
    "plt.plot(trainer.hist_val.acc_list, label = 'g - train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = model_sep_fs\n",
    "trainer = models[mod]\n",
    "plt.plot(trainer.hist_val.acc_c_g,color = 'tab:orange', label = 'g - val')\n",
    "plt.axhline(trainer.hist_val.acc_c_mcp[-1],color = 'tab:blue', label = 'acc_0 - val')\n",
    "plt.axhline(trainer.hist_val.acc_list[-1],color = 'tab:red', label = 'acc_0 - val')\n",
    "#plt.plot(trainer.hist_train.acc_c_mcp, label = 'mcp - train')\n",
    "#plt.plot(trainer.hist_train.acc_c_g, label = 'g - train')\n",
    "#plt.axhline(trainer.hist_val.acc_list[-1],color = 'r', label = 'acc_0 - val')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(trainer.hist_val.g_list)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(trainer.hist_val.loss_list,label = 'Validation')\n",
    "plt.plot(trainer.hist_train.loss_list,label = 'Training')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = model_sep_fs\n",
    "trainer = models[mod]\n",
    "#plt.plot(trainer.hist_train.acc_c_mcp, label = 'mcp - train')\n",
    "plt.plot(trainer.hist_train.acc_c_g,color = 'tab:orange', label = 'g - train')\n",
    "plt.axhline(trainer.hist_train.acc_c_mcp[-1],color = 'tab:blue', label = 'mcp - train')\n",
    "plt.axhline(trainer.hist_train.acc_list[-1],color = 'tab:red', label = 'acc_0 - val')\n",
    "\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(trainer.hist_train.g_list)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(trainer.hist_val.loss_list,label = 'Validation')\n",
    "plt.plot(trainer.hist_train.loss_list,label = 'Training')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = model_sep_fs\n",
    "label, output, g = accumulate_results(mod,train_dataloader)\n",
    "output = torch.exp(output)\n",
    "acc = correct_total(output,label)/label.size(0)\n",
    "g_list = []\n",
    "mcp_list = []\n",
    "ideal = []\n",
    "for c in np.arange(0,1,0.05):\n",
    "    g_list.append(unc_comp.acc_coverage(output,label,1-g,c))\n",
    "    mcp = unc.MCP_unc(output)\n",
    "    mcp_list.append(unc_comp.acc_coverage(output,label,mcp,c))\n",
    "    ideal.append(min(1,acc/(1-c)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(np.arange(0,1,0.05),mcp_list,label = 'mcp')\n",
    "plt.plot(np.arange(0,1,0.05),g_list, label = 'g')\n",
    "plt.plot(np.arange(0,1,0.05),ideal,label = 'ideal')\n",
    "plt.plot(np.arange(0,1,0.05),acc*np.ones(len(g_list)))\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
