{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose, Normalize\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())\n",
    "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transforms_ = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "\n",
    "training_data = datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms_train,\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms_,\n",
    ")\n",
    "\n",
    "train_size = int(0.5*len(training_data))\n",
    "val_size = len(training_data) - train_size\n",
    "training_data, validation_data = random_split(training_data, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 12\n",
    "\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size,shuffle = True)\n",
    "validation_dataloader = DataLoader(validation_data, batch_size=batch_size,shuffle = True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=100)\n",
    "\n",
    "for X, y in train_dataloader:\n",
    "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    break\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "class Model_NN(nn.Module):\n",
    "    \"\"\"CNN.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"CNN Builder.\"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_layer = nn.Sequential(\n",
    "\n",
    "            # Conv Layer block 1\n",
    "            nn.Conv2d(in_channels=3, out_channels=int(32), kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(int(32)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=int(32), out_channels=int(64), kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Conv Layer block 2\n",
    "            nn.Conv2d(in_channels=int(64), out_channels=int(128), kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(int(128)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=int(128), out_channels=int(128), kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout2d(p=0.2),\n",
    "\n",
    "            # Conv Layer block 3\n",
    "            nn.Conv2d(in_channels=int(128), out_channels=int(256), kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(int(256)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=int(256), out_channels=int(256), kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.fc_x_layer = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(4096, int(1024)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(int(1024), int(512)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(int(512), 10),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "        \n",
    "        self.fc_g_layer = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(4096, int(1024)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(int(1024), int(512)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(int(512), 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Perform forward.\"\"\"\n",
    "        \n",
    "        # conv layers\n",
    "        x = self.conv_layer(x)\n",
    "        \n",
    "        # flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # fc layer\n",
    "        #x = self.fc_layer(x)\n",
    "\n",
    "\n",
    "        y = self.fc_x_layer(x)\n",
    "\n",
    "        self.g = self.fc_g_layer(x)\n",
    "\n",
    "        #x = torch.stack((self.x1,self.g))\n",
    "        self.g = (self.g).float()\n",
    "        y = y.float()\n",
    "\n",
    "        \n",
    "\n",
    "        return y\n",
    "    def get_g(self):\n",
    "        return self.g\n",
    "      \n",
    "\n",
    "model = Model_NN()\n",
    "model = model.to(dev)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_params(model, name = None):\n",
    "    for n,param in model.named_parameters():\n",
    "        if name ==None:\n",
    "            param.requires_grad = False\n",
    "        elif name in n:\n",
    "            param.requires_grad = False\n",
    "def unfreeze_params(model, name = None):\n",
    "    for n,param in model.named_parameters():\n",
    "        if name == None:\n",
    "            param.requires_grad = True\n",
    "        elif name in n:\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class rejection_loss(nn.Module):\n",
    "    def __init__(self,criterion, def_loss, no_grad= True):\n",
    "        super().__init__()\n",
    "        self.L0 = def_loss\n",
    "        self.criterion = criterion\n",
    "        self.no_grad = no_grad\n",
    " \n",
    "    def forward(self, y_pred,g,y_true):\n",
    "        \n",
    "        loss = g*self.criterion(y_pred,y_true)+(1-g)*self.L0\n",
    "        loss = torch.mean(loss)\n",
    "        \n",
    "        return loss\n",
    "    def update_L0(self,new_L0):\n",
    "        if self.no_grad:\n",
    "            with torch.no_grad():\n",
    "                self.L0 = new_L0\n",
    "        else: self.L0 = new_L0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predicted_class(y_pred):\n",
    "    '''Returns the predicted class for a given softmax output.'''\n",
    "    if y_pred.shape[-1] == 1:\n",
    "        y_pred = y_pred.view(-1)\n",
    "        y_pred = (y_pred>0.5).float()\n",
    "        \n",
    "    else:\n",
    "        y_pred = torch.max(y_pred, 1)[1]\n",
    "    return y_pred\n",
    "def correct_class(y_pred,y_true):\n",
    "    '''Returns a bool tensor indicating if each prediction is correct'''\n",
    "\n",
    "    y_pred = predicted_class(y_pred)\n",
    "    correct = (y_pred==y_true)\n",
    "    \n",
    "    return correct\n",
    "def correct_total(y_pred,y_true):\n",
    "    '''Returns the number of correct predictions in a batch where dk_mask=0'''\n",
    "    correct = correct_class(y_pred,y_true)\n",
    "    correct_total = torch.sum(correct).item()\n",
    "    return correct_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_acc_g(model,data):\n",
    "    '''Returns the total accuracy of model in some dataset'''\n",
    "    loss_criterion = nn.NLLLoss(reduction = 'sum')\n",
    "    model.eval()\n",
    "    dev = next(model.parameters()).device\n",
    "    total = 0\n",
    "    correct= 0\n",
    "    g_i = 0\n",
    "    bce = 0\n",
    "    with torch.no_grad():\n",
    "        for image,label in data:\n",
    "            image,label = image.to(dev), label.to(dev)\n",
    "            output = model(image)\n",
    "            g = model.get_g()\n",
    "            total += label.size(0)\n",
    "            correct += correct_total(output,label)\n",
    "            g_i += torch.sum(g).item()\n",
    "            bce += loss_criterion(output,label).item()\n",
    "        \n",
    "    return (correct/total),g_i/total, bce/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_eval_layers(layer):\n",
    "    layer.eval()\n",
    "def model_train_layers(layer):\n",
    "    layer.train()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model_NN()\n",
    "model = model.to(dev)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "L0_init = 0\n",
    "#loss_criterion = rejection_loss(CrossEntropy,L0_init)\n",
    "\n",
    "d_mean = defaultdict(list)\n",
    "d_max = defaultdict(list)\n",
    "bce_mean = []\n",
    "L0_list = []\n",
    "g_mean = []\n",
    "mcp_list = []\n",
    "acc_list = []\n",
    "\n",
    "model.train()\n",
    "\n",
    "loss_criterion = nn.NLLLoss(reduction = 'mean')\n",
    "freeze_params(model,'fc_g')\n",
    "n_epochs = 50\n",
    "for epoch in range(n_epochs):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for image,label in train_dataloader:\n",
    "        image,label = image.to(dev), label.to(dev)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(image)\n",
    "        #g = model.get_g()\n",
    "        \n",
    "        loss = loss_criterion(output,label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #L0_list.append(0)\n",
    "        mcp_list.append((torch.mean(torch.max(torch.exp(output),dim=1)[0]).item()))\n",
    "        bce_mean.append(loss_criterion(output,label).item())\n",
    "        \n",
    "        #g_mean.append(torch.mean(g).item())\n",
    "        #g_mm.append(np.mean(g_mean))\n",
    "\n",
    "        total += label.size(0)\n",
    "        correct += correct_total(output,label)\n",
    "        acc_list.append(correct/total)\n",
    "acc, g_i, bce = model_acc_g(model,validation_dataloader) #training_data   \n",
    "loss_criterion = nn.NLLLoss(reduction = 'none')\n",
    "freeze_params(model)\n",
    "unfreeze_params(model,'fc_g')\n",
    "model_eval_layers(model.conv_layer)\n",
    "model_eval_layers(model.fc_x_layer)\n",
    "loss_fn = rejection_loss(loss_criterion,bce,no_grad= True)#np.mean(bce_mean[-4166:]),no_grad= False)\n",
    "acc_m = []\n",
    "g_m = []\n",
    "bce_m = []\n",
    "for epoch in range(5*n_epochs):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for image,label in validation_dataloader:\n",
    "        image,label = image.to(dev), label.to(dev)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(image)\n",
    "        \n",
    "        #bce_mean.append(torch.mean(loss_criterion(output,label)).item())\n",
    "        #loss_fn.update_L0(np.mean(bce_mean[-4166:]))\n",
    "        \n",
    "        g = model.get_g()\n",
    "        loss = loss_fn(output,g,label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        L0_list.append(loss_fn.L0)\n",
    "        bce_mean.append(torch.mean(loss_criterion(output,label)).item())\n",
    "        g_mean.append(torch.mean(g).item())\n",
    "        mcp_list.append((torch.mean(torch.max(torch.exp(output),dim=1)[0]).item()))\n",
    "        \n",
    "        #if (i%5000) == 0:\n",
    "        #loss_fn.update_L0(np.mean(bce_mean[-4166:]))\n",
    "\n",
    "        #loss_criterion.update_L0(torch.mean(CrossEntropy(output,label)).item())\n",
    "\n",
    "        total += label.size(0)\n",
    "        correct += correct_total(output,label)\n",
    "        acc_list.append(correct/total)\n",
    "    acc, g_i, bce = model_acc_g(model,validation_dataloader)\n",
    "    acc_m.append(acc)\n",
    "    g_m.append(g_i)\n",
    "    bce_m.append(bce)\n",
    "        \n",
    "        \n",
    "'''        for n,p in model.named_parameters():\n",
    "            if(p.requires_grad) and (\"bias\" not in n):\n",
    "\n",
    "                d_mean[n].append(p.grad.abs().mean().item())\n",
    "                d_max[n].append(p.grad.abs().max().item())'''\n",
    "                \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(g_m)),g_m,label = 'Média de g',lw=3)\n",
    "plt.plot(np.arange(len(acc_m)),acc_m,label = 'Acurácia',lw=2)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(np.arange(len(bce_m)),bce_m,label = 'BCE',lw=1)\n",
    "plt.plot(L0_list[0:250], label = 'L0',lw = 4)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_decimal(y,n_digits = 1):\n",
    "    '''Round a tensor with n_digits digits'''\n",
    "    rounded = np.around(y,1)\n",
    "    return rounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listg = []\n",
    "listbce = []\n",
    "g_dict = defaultdict(list)\n",
    "for i in round_decimal(np.arange(0,1.1,0.1)):\n",
    "    g_dict[i] = [0,0]\n",
    "for image,label in validation_dataloader:\n",
    "    image,label = image.to(dev), label.to(dev)\n",
    "    output = model(image)\n",
    "    bce = loss_criterion(output,label).cpu().detach().numpy()\n",
    "    g = model.get_g().view(-1).tolist()\n",
    "    g = round_decimal(g)\n",
    "    for i in g_dict:\n",
    "        g_dict[i][0] += np.sum(bce[g==i])\n",
    "        g_dict[i][1] += np.sum(g==i)\n",
    "    listbce.extend(bce)\n",
    "    listg.extend(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in g_dict:\n",
    "    acc=g_dict[i][0]/g_dict[i][1]\n",
    "    plt.bar(i,acc,width=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image,label in test_dataloader:\n",
    "    image,label = image.to(dev), label.to(dev)\n",
    "    output = model(image)\n",
    "    bce = loss_criterion(output,label).tolist()\n",
    "    g = model.get_g().tolist()\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Colocar MCP e TCP também\n",
    "plt.plot(np.arange(len(bce_mean)),bce_mean,label = 'Média de BCE',lw=0.5)\n",
    "plt.plot(np.arange(len(g_mean)),g_mean,label = 'Média de g',lw=3)\n",
    "#plt.plot(it_list,acc_list,label = 'Acurácia',lw=4)\n",
    "plt.plot(np.arange(len(L0_list)),L0_list,label = 'L0',lw=2)\n",
    "#plt.plot(it_list,(np.array(bce_mean)-np.array(L0_list)),label = 'BCE - L0',lw=2)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title('Médias do Output')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "'''for n in d_mean:\n",
    "    plt.bar(np.array(it_list),d_max[n],color=\"b\", label = 'Max (grad)')\n",
    "    plt.plot(np.array(it_list),d_mean[n],color=\"g\", label = 'Média do grad')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.title('Camada: %s'%n)\n",
    "    plt.show()'''\n",
    "\n",
    "print('Acurácia de treino = ',model_acc(model,train_dataloader), 'Acurácia de teste = ',model_acc(model,test_dataloader))\n",
    "\n",
    "\n",
    "plt.plot(np.arange(len(g_mean)),g_mean,label = 'Média de g',lw=3)\n",
    "plt.plot(np.arange(len(acc_list)),acc_list,label = 'Acurácia',lw=4)\n",
    "plt.plot(np.arange(len(L0_list)),L0_list,label = 'L0',lw=2)\n",
    "#plt.plot(it_list,(np.array(bce_mean)-np.array(L0_list)),label = 'BCE - L0',lw=2)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title('Médias do Output')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(g_mean)),g_mean,label = 'Média de g',lw=3)\n",
    "plt.plot(np.arange(len(L0_list)),L0_list,label = 'L0',lw=2)\n",
    "#plt.plot(it_list,(np.array(bce_mean)-np.array(L0_list)),label = 'BCE - L0',lw=2)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title('Médias do Output')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = r'/home/luis-felipe/data/output'\n",
    "file = PATH + '/model_bad_big.csv'\n",
    "a = np.asarray([bce_mean,mcp_list,acc_list])\n",
    "np.savetxt(file, a, delimiter=\",\")\n",
    "\n",
    "file = PATH + '/model_bad_small.csv'\n",
    "a = np.asarray([ g_mean, L0_list])\n",
    "np.savetxt(file, a, delimiter=\",\")\n",
    "\n",
    "# Specify a path\n",
    "PATH = r'/home/luis-felipe/torch_models/test_learned_unc_bad.pt'\n",
    "\n",
    "# Save\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dif_m = []\n",
    "n = 500\n",
    "for j in range(0,len(L0_list),n):\n",
    "    diff = np.mean(((bce_mean)[len(bce_mean)-i:])[j:j+n-1])-np.mean(L0_list[j:j+n-1])\n",
    "    dif_m.append(diff)\n",
    "    \n",
    "plt.plot(range(len(dif_m)),dif_m) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "g_m_test = []\n",
    "g_min = []\n",
    "g_max = []\n",
    "for image,label in test_dataloader:\n",
    "    image,label = image.to(dev), label.to(dev)\n",
    "    y = (model(image))\n",
    "    g = model.get_g()\n",
    "    g_m_test.append(torch.mean(g).item())\n",
    "    g_min.append(torch.min(g).item())\n",
    "    g_max.append(torch.max(g).item())\n",
    "plt.plot(g_m_test)\n",
    "plt.plot(g_min,'ro')\n",
    "plt.plot(g_max,'gx')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "mcp_m_test = []\n",
    "mcp_min = []\n",
    "mcp_max = []\n",
    "for image,label in test_dataloader:\n",
    "    image,label = image.to(dev), label.to(dev)\n",
    "    y = torch.exp(model(image))\n",
    "    MCP = torch.max(y,dim=1)[0]\n",
    "    mcp_m_test.append(torch.mean(MCP).item())\n",
    "    mcp_min.append(torch.min(MCP).item())\n",
    "    mcp_max.append(torch.max(MCP).item())\n",
    "plt.plot(mcp_m_test)\n",
    "plt.plot(mcp_min,'ro')\n",
    "plt.plot(mcp_max,'gx')\n",
    "plt.ylim(0.8,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oi\n"
     ]
    }
   ],
   "source": [
    "print('oi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
